{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】クロスバリデーション\n",
    "* train_test_splitではなく、クロスバリデーションを用いる\n",
    "* クロスバリデーションには、scikit-learnのKFold ライブラリを使用する  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[3 4]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [3 4]] \n",
      "X_test: [[1 2]\n",
      " [1 2]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [3 4]] \n",
      "y_train: [0 1 1 1 1] \n",
      "y_test: [0 1 1 1 1]\n",
      "X_train: [[1 2]\n",
      " [1 2]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [3 4]] \n",
      "X_test: [[3 4]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [3 4]] \n",
      "y_train: [0 1 1 1 1] \n",
      "y_test: [0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [3, 4], [3, 4], [3, 4], [3, 4], [3, 4], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# 2分割\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"X_train:\", X_train, \"\\nX_test:\", X_test, \"\\ny_train:\", y_train, \"\\ny_test:\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Home Credit Default Risk コンペティションのデータセットでやってみる\n",
    "* stratifyする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 61465  61466  61467 ... 307508 307509 307510]\n",
      "[    0     1     2 ... 61814 61816 61828]\n",
      "[     0      1      2 ... 307508 307509 307510]\n",
      "[ 61465  61466  61467 ... 123093 123094 123095]\n",
      "[     0      1      2 ... 307508 307509 307510]\n",
      "[121993 122029 122030 ... 184624 184625 184626]\n",
      "[     0      1      2 ... 307508 307509 307510]\n",
      "[183271 183273 183278 ... 246095 246097 246099]\n",
      "[     0      1      2 ... 246095 246097 246099]\n",
      "[244997 245014 245015 ... 307508 307509 307510]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('../input/application_train.csv')\n",
    "\n",
    "# 説明変数\n",
    "X = df_train.drop(['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "\n",
    "# 目的変数\n",
    "y = df_train['TARGET']\n",
    "\n",
    "# 5分割\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    # すげー出てくるのでコメントアウト\n",
    "    # X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    # y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #print(\"X_train:\", X_train, \"\\nX_test:\", X_test, \"\\ny_train:\", y_train, \"\\ny_test:\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】グリッドサーチ\n",
    "* グリッドサーチをパイプラインの中に組み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 訓練データ\n",
    "df_train = pd.read_csv('../input/application_train.csv')\n",
    "\n",
    "# 説明変数(week3のeda結果より抜粋)\n",
    "X = df_train.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                    'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_BIRTH']]\n",
    "\n",
    "# 欠損を平均値で埋める\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# 目的変数\n",
    "y = df_train['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'C': 0.001, 'solver': 'lbfgs'}\n",
      "Best cross-validation score : 0.591\n",
      "LogisticRegression Best AUC:0.5900027129004467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "gred_params = {'C' : [0.001, 0.01, 0.1, 1, 10, 100], 'solver' : ['lbfgs']}\n",
    "\n",
    "# cvでn_splitsを指定してクロスバリデーションされる\n",
    "clf = GridSearchCV(LogisticRegression(), gred_params, cv=5, scoring='roc_auc')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters : {}\".format(clf.best_params_))\n",
    "print(\"Best cross-validation score : {:.3f}\".format(clf.best_score_))\n",
    "print(\"LogisticRegression Best AUC:{}\".format(roc_auc_score(y_test, clf.decision_function(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 脱線\n",
    "- ついでにパイプラインを修正してクラス化してみたくなった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TODO:看板とかコメントちゃんとつける\n",
    "class CPL():\n",
    "    \"\"\"\n",
    "    分類汎用パイプライン\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_: df\n",
    "        説明変数たち\n",
    "    y_: df\n",
    "        目的変数\n",
    "    score_ : dict\n",
    "        評価値\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "    \n",
    "    \n",
    "    def split(self, train_size=0.8):\n",
    "        self.X_train_, self.X_test_, self.y_train_, self.y_test_ = train_test_split(self.X_, self.y_, train_size=train_size)\n",
    "    \n",
    "            \n",
    "    def cross_validate(self, model, n_splits):\n",
    "        skf = StratifiedKFold(n_splits=n_splits)\n",
    "        \n",
    "        auc_scores = []\n",
    "        \n",
    "        for train_index, test_index in skf.split(self.X_, self.y_):\n",
    "            self.X_train_, self.X_test_ = self.X_.iloc[train_index], self.X_.iloc[test_index]\n",
    "            self.y_train_, self.y_test_ = self.y_.iloc[train_index], self.y_.iloc[test_index]\n",
    "            \n",
    "            model.fit(self.X_train_, self.y_train_)\n",
    "            \n",
    "            self._calc_auc(model)\n",
    "            \n",
    "            auc_scores.append(self.auc_)\n",
    "            \n",
    "            \n",
    "        return auc_scores\n",
    "    \n",
    "        \n",
    "    def grid_search_cv(self, model, grid_params, cv=5, scoring='roc_auc'):\n",
    "        self.clf_ = GridSearchCV(\n",
    "            model,\n",
    "            grid_params,\n",
    "            cv=cv,\n",
    "            scoring='roc_auc')\n",
    "        \n",
    "        self.clf_.fit(self.X_, self.y_)\n",
    "        \n",
    "        self.best_params_ = self.clf_.best_params_\n",
    "        \n",
    "        self.y_pred_ = self.clf_.predict_proba(self.X_test_)[:,1]\n",
    "        \n",
    "        self.best_auc_ = metrics.roc_auc_score(self.y_test_, self.y_pred_)\n",
    "    \n",
    "    \n",
    "    def generate_pred_for_submission(self, test):\n",
    "        self.y_pred_ = self.clf_.predict_proba(test)[:,1]\n",
    "        \n",
    "        return self.y_pred_\n",
    "        \n",
    "    \n",
    "    def _calc_auc(self, model):\n",
    "        # 予測\n",
    "        self.y_pred_ = model.predict_proba(self.X_test_)[:,1]\n",
    "        \n",
    "        # FPR, TPR(, しきい値) を算出\n",
    "        self.fpr_, self.tpr_, self.thresholds_ = metrics.roc_curve(self.y_test_, self.y_pred_)\n",
    "        \n",
    "        # auc算出\n",
    "        self.auc_ = metrics.roc_auc_score(self.y_test_, self.y_pred_)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦ここまでで中止、、随時拡張していきたい  \n",
    "様々なモデルでクロスバリデーションを試してみる(重たいので、複数セルで実施)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ\n",
    "df_train = pd.read_csv('../input/application_train.csv')\n",
    "\n",
    "# 説明変数(week3のeda結果より抜粋)\n",
    "X = df_train.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                    'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_BIRTH']]\n",
    "\n",
    "# 欠損を平均値で埋める\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# 目的変数\n",
    "y = df_train.loc[:, 'TARGET']\n",
    "\n",
    "\n",
    "# 自作クラスインスタンス化\n",
    "cpl = CPL(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.729342152647506, 0.7305931623421007, 0.7242335148950484, 0.7327486098855563, 0.7338617452364475]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "\n",
    "# クロスバリデーション実施\n",
    "auc_scores = cpl.cross_validate(model, 5)\n",
    "print(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5217685441587523, 0.522762040475735, 0.5274385420158417, 0.5230404151557675, 0.5240136871929852]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "# クロスバリデーション実施\n",
    "auc_scores = cpl.cross_validate(model, 5)\n",
    "print(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5904042151226117, 0.5899166425622833, 0.5916606367857098, 0.5900143390132754, 0.5913547938849446]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "\n",
    "# クロスバリデーション実施\n",
    "auc_scores = cpl.cross_validate(model, 5)\n",
    "print(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5359610182238206, 0.5402660461317554, 0.5359451477034504, 0.5344782225245075, 0.5407367624809006]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# クロスバリデーション実施\n",
    "auc_scores = cpl.cross_validate(model, 5)\n",
    "print(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6328369280780669, 0.6371727283335258, 0.6297689554101591, 0.6300951469882898, 0.6350958344508273]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# クロスバリデーション実施\n",
    "auc_scores = cpl.cross_validate(model, 5)\n",
    "print(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異様に重いので不実施\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "#clf = SVC()\n",
    "\n",
    "\n",
    "# クロスバリデーション実施\n",
    "#auc_scores = cpl.cross_validate(clf, 5)\n",
    "#print(auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアが高かったlightgbmで\n",
    "グリッドサーチ+クロスバリデーションを試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__num_leaves': 2}\n",
      "0.7528421498334035\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "grid_params = {'lgb__num_leaves': range(2, 41, 5)}\n",
    "\n",
    "cpl.split()\n",
    "\n",
    "cpl.grid_search_cv(model, grid_params)\n",
    "\n",
    "print(cpl.best_params_)\n",
    "print(cpl.best_auc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大体同じくらい  \n",
    "この状態で提出してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_test = pd.read_csv(\"../input/application_test.csv\")\n",
    "\n",
    "X_test = df_test.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                                         'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_BIRTH']]\n",
    "\n",
    "# 提出用\n",
    "submission = pd.DataFrame({'SK_ID_CURR': df_test['SK_ID_CURR'], \n",
    "                           'TARGET': cpl.generate_pred_for_submission(X_test)})\n",
    "\n",
    "# タイムスタンプ作成\n",
    "time_stamp = datetime.now().strftime('%Y%m%d%H%M')\n",
    "submission.to_csv('home_credit_' + time_stamp + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prt :0.66706 Pub0.66061とaucよりだいぶ低くなった、、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】Kernelからの調査\n",
    "- 特徴量の選出・加工が微妙っぽいので、EDA・特徴量エンジニアリングを調査してやりたい\n",
    "\n",
    "# 【問題4】高い汎化性能のモデル\n",
    "- lgbmが良さそうなのはわかったので(アプローチは正しくないかもしれない、、)  \n",
    "lgbmでグリッドサーチを引き続きやりたい  \n",
    "<br><br>\n",
    "- まずはEDAから。色々プロットするのも手間なので、すでにあるカーネルを参考にする\n",
    "https://www.kaggle.com/codename007/home-credit-complete-eda-feature-importance\n",
    "https://www.kaggle.com/gpreda/home-credit-default-risk-extensive-eda\n",
    "- プロットの仕方も色々あることがわかった、みやすいのも多くあったので、今度試してみる\n",
    "- PCA(主成分分析)  \n",
    "→ 次元を圧縮するのに使う、処理が軽くなるのか？ 次回以降で調査してやってみる\n",
    "- application_train・test以外のファイルにも有益な情報が多そうだった  \n",
    "→ bureau・bureau_balanceが有益そう こちらも今回はパス\n",
    "- 新たな特徴量？を作成してグラフ化してる方が多かった  \n",
    "→ これはちょっと試したい\n",
    "<br><br>\n",
    "次に特徴量エンジニアリング、カーネルから自分になかったアイデアを列挙する。  \n",
    "<br>\n",
    "- 特徴量の作成\n",
    "下記が参考になりそう。  \n",
    "https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features#L61-L68  \n",
    "week3から重要度が高い特徴量でもあるので、まんま流用してみる。　　\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_CREDIT_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "      <th>ANNUITY_INCOME_PERC</th>\n",
       "      <th>PAYMENT_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>0.498036</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.060749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.208736</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.132217</td>\n",
       "      <td>0.027598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159905</td>\n",
       "      <td>0.431748</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.094941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>0.042623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  DAYS_EMPLOYED_PERC  \\\n",
       "0      0.083037      0.262949      0.139376            0.067329   \n",
       "1      0.311267      0.622246           NaN            0.070862   \n",
       "2           NaN      0.555912      0.729567            0.011814   \n",
       "3           NaN      0.650442           NaN            0.159905   \n",
       "4           NaN      0.322738           NaN            0.152418   \n",
       "\n",
       "   INCOME_CREDIT_PERC  INCOME_PER_PERSON  ANNUITY_INCOME_PERC  PAYMENT_RATE  \n",
       "0            0.498036           202500.0             0.121978      0.060749  \n",
       "1            0.208736           135000.0             0.132217      0.027598  \n",
       "2            0.500000            67500.0             0.100000      0.050000  \n",
       "3            0.431748            67500.0             0.219900      0.094941  \n",
       "4            0.236842           121500.0             0.179963      0.042623  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データ\n",
    "df = pd.read_csv('../input/application_train.csv')\n",
    "\n",
    "#　以下流用\n",
    "# NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "# Some simple new features (percentages)\n",
    "df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "\n",
    "\n",
    "# 説明変数(EXT_SOURCEシリーズ+作成した特徴量を採用)\n",
    "X = df.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                    'DAYS_EMPLOYED_PERC', 'INCOME_CREDIT_PERC', 'INCOME_PER_PERSON',\n",
    "                    'ANNUITY_INCOME_PERC', 'PAYMENT_RATE']]\n",
    "\n",
    "\n",
    "# 目的変数\n",
    "y = df.loc[:, 'TARGET']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おkそう  \n",
    "試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__num_leaves': 2}\n",
      "0.7763226601076023\n"
     ]
    }
   ],
   "source": [
    "# 自作クラスインスタンス化\n",
    "cpl = CPL(X, y)\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "grid_params = {'lgb__num_leaves': range(2, 41, 5)}\n",
    "\n",
    "cpl.split()\n",
    "\n",
    "cpl.grid_search_cv(model, grid_params)\n",
    "\n",
    "print(cpl.best_params_)\n",
    "print(cpl.best_auc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上がったので、この状態で提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_test = pd.read_csv(\"../input/application_test.csv\")\n",
    "\n",
    "#　以下流用\n",
    "# NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "df_test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "# Some simple new features (percentages)\n",
    "df_test['DAYS_EMPLOYED_PERC'] = df_test['DAYS_EMPLOYED'] / df_test['DAYS_BIRTH']\n",
    "df_test['INCOME_CREDIT_PERC'] = df_test['AMT_INCOME_TOTAL'] / df_test['AMT_CREDIT']\n",
    "df_test['INCOME_PER_PERSON'] = df_test['AMT_INCOME_TOTAL'] / df_test['CNT_FAM_MEMBERS']\n",
    "df_test['ANNUITY_INCOME_PERC'] = df_test['AMT_ANNUITY'] / df_test['AMT_INCOME_TOTAL']\n",
    "df_test['PAYMENT_RATE'] = df_test['AMT_ANNUITY'] / df_test['AMT_CREDIT']\n",
    "\n",
    "\n",
    "# 説明変数(EXT_SOURCEシリーズ+作成した特徴量を採用)\n",
    "X_test = df_test.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                    'DAYS_EMPLOYED_PERC', 'INCOME_CREDIT_PERC', 'INCOME_PER_PERSON',\n",
    "                    'ANNUITY_INCOME_PERC', 'PAYMENT_RATE']]\n",
    "\n",
    "# 提出用\n",
    "submission = pd.DataFrame({'SK_ID_CURR': df_test['SK_ID_CURR'], \n",
    "                           'TARGET': cpl.generate_pred_for_submission(X_test)})\n",
    "\n",
    "# タイムスタンプ作成\n",
    "time_stamp = datetime.now().strftime('%Y%m%d%H%M')\n",
    "submission.to_csv('home_credit_' + time_stamp + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prt :0.74124 Pub 0.75443  \n",
    "とめっちゃ上がった。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最後にグリッドサーチして一番スコアがよかったものを採用して提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自作クラスインスタンス化\n",
    "cpl = CPL(X, y)\n",
    "\n",
    "grid_params = {\n",
    "        'lgb__num_leaves': [2],\n",
    "        'n_estimators' : range(10,210,100),\n",
    "        'objective':['binary'], # 二項分類\n",
    "        'random_state' :[0]}\n",
    "\n",
    "cpl.split()\n",
    "\n",
    "cpl.grid_search_cv(model, grid_params)\n",
    "\n",
    "print(cpl.best_params_)\n",
    "print(cpl.best_auc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_test = pd.read_csv(\"../input/application_test.csv\")\n",
    "\n",
    "#　以下流用\n",
    "# NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "df_test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "# Some simple new features (percentages)\n",
    "df_test['DAYS_EMPLOYED_PERC'] = df_test['DAYS_EMPLOYED'] / df_test['DAYS_BIRTH']\n",
    "df_test['INCOME_CREDIT_PERC'] = df_test['AMT_INCOME_TOTAL'] / df_test['AMT_CREDIT']\n",
    "df_test['INCOME_PER_PERSON'] = df_test['AMT_INCOME_TOTAL'] / df_test['CNT_FAM_MEMBERS']\n",
    "df_test['ANNUITY_INCOME_PERC'] = df_test['AMT_ANNUITY'] / df_test['AMT_INCOME_TOTAL']\n",
    "df_test['PAYMENT_RATE'] = df_test['AMT_ANNUITY'] / df_test['AMT_CREDIT']\n",
    "\n",
    "\n",
    "# 説明変数(EXT_SOURCEシリーズ+作成した特徴量を採用)\n",
    "X_test = df_test.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "                    'DAYS_EMPLOYED_PERC', 'INCOME_CREDIT_PERC', 'INCOME_PER_PERSON',\n",
    "                    'ANNUITY_INCOME_PERC', 'PAYMENT_RATE']]\n",
    "\n",
    "# 提出用\n",
    "submission = pd.DataFrame({'SK_ID_CURR': df_test['SK_ID_CURR'], \n",
    "                           'TARGET': cpl.generate_pred_for_submission(X_test)})\n",
    "\n",
    "# タイムスタンプ作成\n",
    "time_stamp = datetime.now().strftime('%Y%m%d%H%M')\n",
    "submission.to_csv('home_credit_' + time_stamp + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "以降のアプローチは下記を試したい\n",
    "- application_train・test以外のファイルを調査  \n",
    "→ bureau・bureau_balanceが有益そう\n",
    "- Null Importances なるものがあったのでこれも試してみたい \n",
    "https://www.kaggle.com/ogrellier/feature-selection-with-null-importances\n",
    "- (PCA(主成分分析))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
