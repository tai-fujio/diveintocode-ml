{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】線形回帰のクラスを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "          Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "        return\n",
    "\n",
    "    \n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          学習データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return\n",
    "    \n",
    "    def MSE(y_pred, y):\n",
    "        \"\"\"\n",
    "        平均二乗誤差の計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : 次の形のndarray, shape (n_samples,)\n",
    "          推定した値\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "          正解値\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        mse : numpy.float\n",
    "          平均二乗誤差\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return mse\n",
    "    \n",
    "    \n",
    "    def _gradient_descent(self, X, error):\n",
    "        \"\"\"\n",
    "        説明を記述\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各関数でやっていること\n",
    "- \\_linear_hypothesis(X)\n",
    "線形回帰の仮定関数  \n",
    "\n",
    "    $h_\\theta(x) =  \\theta_0 x_0 + \\theta_1 x_1 + ... + \\theta_j x_j + ... +\\theta_n x_n.   (x_0 = 1)\\$\n",
    "\n",
    "    $x$ : 特徴量ベクトル\n",
    "\n",
    "    $θ$ : パラメータベクトル\n",
    "\n",
    "    $n$ : 特徴量の数\n",
    "\n",
    "    $x_j$ : j番目の特徴量\n",
    "\n",
    "    $θ_j$ : j番目のパラメータ（重み）\n",
    "    \n",
    "    ベクトル形式で表すと以下  \n",
    "    $h_\\theta(x) = \\theta^T \\cdot x.$\n",
    "<br><br>\n",
    "\n",
    "\n",
    " - MSE(y_pred, y)\n",
    " 線形回帰の仮定関数\n",
    " \n",
    "    $J(\\theta)=  \\frac{1 }{ 2m}  \\sum_{i=1}^{m}. (h_\\theta(x^{(i)})-y^{(i)})^2.$\n",
    "     \n",
    "    $m$ : 入力されるデータの数\n",
    "\n",
    "    $h_\\theta()$ : 仮定関数\n",
    "\n",
    "    $x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "    $y^{(i)}$ : i番目のサンプルの正解値\n",
    " <br><br>\n",
    " \n",
    " \n",
    " - \\_gradient_descent(self, X, error)\n",
    " 最急降下法\n",
    " \n",
    "     $\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}[(h_\\theta(x^{(i)}) - y^{(i)} )x_{j}^{(i)}]$\n",
    "     \n",
    "     $α$ : 学習率\n",
    "\n",
    "     $i$ : サンプルのインデックス\n",
    "\n",
    "     $j$ : 特徴量のインデックス\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】学習曲線のプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】スクラッチで学べることは何か"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
