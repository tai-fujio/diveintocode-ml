{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I42U2SVLjKlT"
   },
   "source": [
    "### 下ごしらえ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiM0zbb3jKlU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iR5h_A2VjKla"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 平坦化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 学習データをスプリット\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7gjdnOspe-i"
   },
   "source": [
    "## GetMiniBatchクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdzSVH9GpeMP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "py2LixrIjKlc"
   },
   "source": [
    "## 【問題1】全結合層のクラス化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10orqXDSjKld"
   },
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.initializer = initializer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes1 = n_nodes2\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.Z = None\n",
    "        self.dA = None \n",
    "        \n",
    "\n",
    "    def forward(self, Z):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        \n",
    "        # backwardで使うためインスタンス変数化\n",
    "        self.Z = Z\n",
    "        \n",
    "        A = (Z @ self.W) + self.B\n",
    "        \n",
    "        return A\n",
    "      \n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        # 重みインスタンス変数化\n",
    "        self.dA = dA\n",
    "        \n",
    "        dZ = (dA @ self.W.T)\n",
    "        \n",
    "        # self.W self.Bの更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEOBg5-TqlMz"
   },
   "source": [
    "## 【問題2】初期化方法のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JrWpsunYkcSI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
    "          重さ\n",
    "        \"\"\"\n",
    "        \n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "\n",
    "        return W\n",
    "\n",
    "\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :次の形のndarray, shape (n_nodes2,)\n",
    "          バイアス\n",
    "        \"\"\"\n",
    "        \n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKiH50V1FXp7"
   },
   "source": [
    "## 【問題3】最適化手法のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mG1FXFHXkgsI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        \n",
    "        # 重みとバイアスを更新\n",
    "        layer.W -= self.lr * layer.Z.T @ layer.dA\n",
    "        layer.B -= np.mean(layer.dA, axis=0)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2FICQa-Fc5z"
   },
   "source": [
    "## 【問題4】活性化関数のクラス化\n",
    "## 【問題5】ReLUクラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxO5bKU1kjGD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"\n",
    "    シグモイド関数汎用クラス\n",
    "    \n",
    "    \"\"\"\n",
    "      \n",
    "    def forward(self, A):\n",
    "        # 入力の最大値\n",
    "        sigmoid_range = 34.538776394910684\n",
    "        \n",
    "        Z = 1 / (1 + np.exp(-np.clip(A, -sigmoid_range, sigmoid_range)))\n",
    "        \n",
    "        return Z\n",
    "      \n",
    "\n",
    "    def backward(self, Z):\n",
    "        return self.forward(Z) * (1 - self.forward(Z))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5y7HYGspNXJ9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"\n",
    "    ソフトマックス汎用クラス\n",
    "    \n",
    "    \"\"\"\n",
    "      \n",
    "    def forward(self, X):\n",
    "        max_X = np.max(X)\n",
    "        exp_X = np.exp(X - max_X)\n",
    "        sum_exp_X = np.sum(exp_X, axis=1).reshape(-1, 1)\n",
    "        \n",
    "        Z = exp_X / sum_exp_X\n",
    "        \n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LnV7aQiwJPd7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO\n",
    "\n",
    "class ReLU:\n",
    "    \"\"\"\n",
    "    ReLU汎用クラス\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "\n",
    "      \n",
    "\n",
    "    def backward(Z):\n",
    "        return self.forward(Z) * (1 - self.forward(Z))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YyCpq_mIlCMl"
   },
   "source": [
    "## ScratchDeepNeuralNetworkClassifierクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtI7w4kUlAe2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging                                                                     # ログ\n",
    "from datetime import datetime                                        # 時間のやつ\n",
    "from sklearn.preprocessing import OneHotEncoder       # ワンホットのやつ\n",
    "from tqdm import tqdm                                                     # 進捗バーを出してくれるやつ\n",
    "\n",
    "\n",
    "class ScratchDeepNeuralNetworkClassifier():\n",
    "    \"\"\"\n",
    "    ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "        学習過程を出力する場合はTrue\n",
    "    epochs : int\n",
    "        エポック数（イテレーション数）\n",
    "    batch_size : int\n",
    "        バッチサイズ\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.loss_ : dict\n",
    "        イテレーションごとのcostとaccuracy\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=10, n_epochs=50,  n_nodes=400, layer=4, verbose=True,\n",
    "                            sigma=1e-2, lr=1e-2, activation=None):\n",
    "        self.batch_size = batch_size     # バッチサイズ\n",
    "        self.n_epochs = n_epochs         # エポック数 \n",
    "        self.n_input = n_nodes              # 初回のノード数\n",
    "        self.layer = layer                          # 層の数\n",
    "        self.verbose = verbose               # 学習過程出力フラグ\n",
    "        self.loss_ = []                              # 学習用データの学習過程格納用\n",
    "        self.loss_val_ = []                       # 検証用データの学習過程格納用\n",
    "        self.FCs = []                                  # FCインスタンス格納用\n",
    "        \n",
    "        # 初期化・最適化クラスインスタンス作成\n",
    "        self.initializer = SimpleInitializer(sigma)\n",
    "        self.optimizer = SGD(lr)\n",
    "        # ワンホットライブラリのインスタンス作成\n",
    "        self.enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        \n",
    "        # アクティベーションをインスタンス化(デフォルトReLU)\n",
    "        #self.activation = ReLU()\n",
    "        # 引数で指定された場合は他の活性化関数クラスのインスタンス作成\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = Sigmoid()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = Tanh()\n",
    "        # 最後はsoftmaxで\n",
    "        self.activation_final = Softmax()\n",
    "        # ログレベルを DEBUG に変更\n",
    "        time_stamp = datetime.now().strftime('%Y%m%d')\n",
    "        logging.basicConfig(filename='../log/' + time_stamp + '.log', level=logging.DEBUG)\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # ワンホット化\n",
    "        y = self.enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        # 検証用データがある場合\n",
    "        if X_val is not None:\n",
    "            y_val= self.enc.fit_transform(y_val[:, np.newaxis])\n",
    "        \n",
    "        # 学習用データから特徴量とクラス数を取得\n",
    "        n_features = X.shape[1]\n",
    "        n_output = y.shape[1]\n",
    "        \n",
    "        # 初期化\n",
    "        n_nodes1 = self.n_input\n",
    "        \n",
    "        # 各層のFCインスタンス作成\n",
    "        for i in range(self.layer):\n",
    "            if i == 0:                              # 入力層\n",
    "                fc = FC(n_features, n_nodes1, self.initializer, self.optimizer)\n",
    "            elif i == (self.layer - 1):     # 出力層\n",
    "                fc = FC(n_nodes2, n_output, self.initializer, self.optimizer)\n",
    "            else:\n",
    "                # TODO: 多分よロしくない\n",
    "                n_nodes2 = int(n_nodes1 / 2)\n",
    "                fc = FC(n_nodes1, n_nodes2, self.initializer, self.optimizer)\n",
    "                n_nodes1 = n_nodes2\n",
    "                \n",
    "            self.FCs.append(fc)          # 格納\n",
    "\n",
    "\n",
    "        # エポックごとに進捗率を計測\n",
    "        for e in tqdm(range(self.n_epochs)):\n",
    "            # ミニバッチ化\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "            # ロス格納用\n",
    "            loss = []\n",
    "            \n",
    "            # Xのn_samples / batch_size数分ループ処理\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # forward propagation\n",
    "                for i in range(self.layer):\n",
    "                    if i == 0:                              # 入力層\n",
    "                        A = self.FCs[i].forward(mini_X_train)\n",
    "                        Z = self.activation.forward(A)\n",
    "                    elif i == (self.layer - 1):     # 出力層\n",
    "                        A = self.FCs[i].forward(Z)\n",
    "                        Z = self.activation_final.forward(A)\n",
    "                    else:\n",
    "                        A = self.FCs[i].forward(Z)\n",
    "                        Z = self.activation.forward(A)                \n",
    "                \n",
    "                # back propagation\n",
    "                for i in range(self.layer):\n",
    "                    n_FC = self.layer - i - 1      # FCインスタンス指定用\n",
    "                    if i == 0:                               # 入力層\n",
    "                        dA = Z - mini_y_train     # TODO:ソフトマックス関数のバックプロパゲーションに交差エントロピー誤差の計算も含む実装\n",
    "                        dZ = self.FCs[n_FC].backward(A)\n",
    "                        loss.append(self._cross_entropy(Z, mini_y_train))\n",
    "                    else:                                     # 出力層\n",
    "                        dA = self.activation.backward(dZ)\n",
    "                        dZ = self.FCs[n_FC].backward(dA)\n",
    "            \n",
    "\n",
    "            # 誤差を格納\n",
    "            self.loss_.append(np.sum(loss))\n",
    "            \n",
    "            # 検証用データがある場合\n",
    "            if X_val is not None:\n",
    "                pass\n",
    "                \n",
    "                loss_val = cross_entropy(y_val, Z3)\n",
    "\n",
    "                self.loss_val_.append(loss_val)\n",
    "            \n",
    "            if self.verbose:\n",
    "                logging.info('forward propagation %sエポック目 sum: %s shape: %s', e+1, np.sum(A), A.shape)\n",
    "                logging.info('forward propagation %sエポック目 sum: %s shape: %s', e+1, np.sum(Z), Z.shape)\n",
    "                logging.info('forward propagation %sエポック目 sum: %s shape: %s', e+1, np.sum(dA), dA.shape)\n",
    "                logging.info('forward propagation %sエポック目 sum: %s shape: %s', e+1, np.sum(dZ), dZ.shape)\n",
    "                    \n",
    "        return self\n",
    "\n",
    "    \n",
    "    def _cross_entropy(self, y_pred, y_true):\n",
    "        return (-1) * np.sum(y_true * np.log(y_pred))\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred :  次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        # フォワードプロパゲーション\n",
    "        pass\n",
    "        \n",
    "        # 一番確率が高いラベルを予測値に\n",
    "        y_pred = np.argmax(Z3, axis=1)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "id": "81fkk2k0Hq5Z",
    "outputId": "fc98c649-583f-4df7-b150-0e2b89fcebc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110524.31400166763]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sdnnc = ScratchDeepNeuralNetworkClassifier(n_epochs=1, activation='sigmoid')\n",
    "sdnnc.fit(X_train, y_train)\n",
    "print(sdnnc.loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MoYiwEKmjKlf"
   },
   "source": [
    "### 寄り道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kwdfFMsjKlf"
   },
   "outputs": [],
   "source": [
    "# ログを出す\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# タイムスタンプ作成\n",
    "time_stamp = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# ログレベルを DEBUG に変更\n",
    "logging.basicConfig(filename='../log/' + time_stamp + '.log', level=logging.DEBUG)\n",
    "\n",
    "logging.info('info %s %s', 'hoge', 'fuga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egHnlVwJjKli"
   },
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    sigmoid_range = 34.538776394910684     # 入力の最大値\n",
    "    return 1 / (1 + np.exp(-np.clip(X, -sigmoid_range, sigmoid_range)))\n",
    "\n",
    "X = np.array([1,5,6,1,3])\n",
    "\n",
    "start = time.time()\n",
    "X = sigmoid(X)\n",
    "process_time = time.time() - start\n",
    "logging.info('sigmoid %s', process_time)\n",
    "\n",
    "def sigmoid_derivative(X):\n",
    "    return sigmoid(X) * (1 - sigmoid(X))\n",
    "\n",
    "start = time.time()\n",
    "X = sigmoid(X)\n",
    "process_time = time.time() - start\n",
    "logging.info('sigmoid_derivative %s', process_time)\n",
    "\n",
    "X = np.array([[1,5,6,1,3],[2,4,5,1,2]])\n",
    "\n",
    "def softmax(X):\n",
    "    max_X = np.max(X)\n",
    "    exp_X = np.exp(X - max_X)\n",
    "    sum_exp_X = np.sum(exp_X, axis=1).reshape(-1, 1)\n",
    "    return exp_X / sum_exp_X\n",
    "\n",
    "start = time.time()\n",
    "X = softmax(X)\n",
    "process_time = time.time() - start\n",
    "logging.info('softmax %s', process_time)\n",
    "\n",
    "X = np.array([1,5,6,1,3])\n",
    "y = np.array([4,5,2,1,3])\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    return (-1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "start = time.time()\n",
    "X = cross_entropy(X, y)\n",
    "process_time = time.time() - start\n",
    "logging.info('cross_entropy %s', process_time)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sprint11-dl-scratch-deep-neural-netowrok.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
