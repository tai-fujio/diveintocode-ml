{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint16-paper-reading.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKErMSHtB9DU",
        "colab_type": "text"
      },
      "source": [
        "## 論文読解\n",
        "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99\n",
        "\n",
        "https://arxiv.org/pdf/1506.01497.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BznPFfykCd_C",
        "colab_type": "text"
      },
      "source": [
        "## 要点\n",
        "### (1) 物体検出の分野にはどういった手法が存在したか。  \n",
        "<br>\n",
        "→ abstractにSPPnet・Fast R-CNNなどの手法によって、ランニングタイムの短縮がなされてきたと記載されている。  \n",
        "\n",
        "#### 参考箇所：\n",
        "> Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region\n",
        "proposal computation as a bottleneck. \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S5ih54kSUqJ",
        "colab_type": "text"
      },
      "source": [
        "### (2) Fasterとあるが、どういった仕組みで高速化したのか。  \n",
        "<br>\n",
        "Faster R-CNNは畳み込み式の手法であるRPN(Region Proposal Networks)とFast R-CNNをマージ・共有し、単一のネットワークとして統合されたもの。\n",
        "RPNのコンポーネントにより統合されたネットワークのどこを見るかを提案する仕組みにすることでGPU上で5fps(5枚/秒)を実現している。  \n",
        "\n",
        "#### 参考箇所：\n",
        "> An RPN is a fully convolutional\n",
        "network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to\n",
        "generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN\n",
        "into a single network by sharing their convolutional features—using the recently popular terminology of neural networks with\n",
        "“attention” mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3],\n",
        "our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection.....\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRwkNFpKSV2q",
        "colab_type": "text"
      },
      "source": [
        "### (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。  \n",
        "<br>\n",
        "→ One-Stageは1windowごとに回帰・分類させてクラスの検出をさせる手法。  \n",
        "対して、Two-Stageはクラスに寄らない物体領域の提案とクラスの検出の2stageからなる手法。 \n",
        "\n",
        "#### 参考箇所：\n",
        ">The OverFeat paper [9] proposes a detection\n",
        "method that uses regressors and classifiers on sliding\n",
        "windows over convolutional feature maps. OverFeat\n",
        "is a one-stage, class-specific detection pipeline, and ours\n",
        "is a two-stage cascade consisting of class-agnostic proposals and class-specific detections. \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4rLMz6VSV5C",
        "colab_type": "text"
      },
      "source": [
        "### (4) RPNとは何か。\n",
        "<br>\n",
        "RPN(Region Proposal Networks)とはend-to-endで学習し、high-qualityな物体境界を検出・提案する手法。  \n",
        "\n",
        "#### 参考箇所：\n",
        ">The RPN is trained end-to-end to\n",
        "generate high-quality region proposals, which are used by Fast R-CNN for detection. \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8W5yIVlSV7M",
        "colab_type": "text"
      },
      "source": [
        "### (5) RoIプーリングとは何か。\n",
        "<br>\n",
        "ROIプーリングのレイヤーは畳み込み処理を行った特徴量マップとregion proposalによる境界線ボックスをインプットとする。  \n",
        "つまり、任意のボックスサイズの領域をプーリングして、固定されたサイズを出力することが目的となる。  \n",
        "backpropagationの勾配はボックス座標に準拠している必要があるとのこと。  \n",
        "\n",
        "#### 参考箇所：\n",
        ">The RoI pooling layer\n",
        "[2] in Fast R-CNN accepts the convolutional features\n",
        "and also the predicted bounding boxes as input, so\n",
        "a theoretically valid backpropagation solver should\n",
        "also involve gradients w.r.t. the box coordinates. These\n",
        "gradients are ignored in the above approximate joint\n",
        "training. In a non-approximate joint training solution,\n",
        "we need an RoI pooling layer that is differentiable\n",
        "w.r.t. the box coordinates.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_iazodjSV9I",
        "colab_type": "text"
      },
      "source": [
        "### (6) Anchorのサイズはどうするのが適切か。\n",
        "<br>\n",
        "\n",
        "Anchorのサイズには下記の3つのアスペクト比 を用いることが適切とされている。  \n",
        "1:1  \n",
        "1:2  \n",
        "2:1  \n",
        "スケールは通常~2400pxまでのW * Hが用いられ、論文では1:1, 1:2, 2:1の三つのアスペクト比と1282, 2562, 5122 pxの三つのスケールからなる9つのAnchorが用いられている。\n",
        "\n",
        "\n",
        "#### 参考箇所：  \n",
        ">For anchors, we use 3 scales with box areas of 1282, 2562, and 5122 pixels, and 3 aspect ratios of 1:1, 1:2, and 2:1. These hyper-parameters are not carefully chosen for a particular dataset, and...\n",
        "<br>\n",
        "<br>\n",
        ">An anchor is centered at the sliding window in question, and is associated with a scale and aspect ratio (Figure 3, left). By default we use 3 scales and 3 aspect ratios, yielding k = 9 anchors at each sliding position. For a convolutional feature map of a size W × H (typically ∼2,400), there are W Hk anchors in total.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cslbji7YSV_c",
        "colab_type": "text"
      },
      "source": [
        "### (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。\n",
        "<br>\n",
        "下記はPASCAL VOC 2012 test setというデータセットを使用し、検出した際の精度。(指標値はmAP: mean Average Precision)  \n",
        "RPNを用いたFaster R-CNNの方が精度が良くなっていることがわかる。\n",
        "\n",
        "#### 参考箇所1：  \n",
        ">Table 4: Detection results on PASCAL VOC 2012 test set. The detector is Fast R-CNN and VGG-16. Training\n",
        "data: “07”: VOC 2007 trainval, “07++12”: union set of VOC 2007 trainval+test and VOC 2012 trainval. For\n",
        "RPN, the train-time proposals for Fast R-CNN are 2000.   \n",
        "†\n",
        ": http://host.robots.ox.ac.uk:8080/anonymous/HZJTQA.html.  \n",
        "‡\n",
        ":\n",
        "http://host.robots.ox.ac.uk:8080/anonymous/YNPLXB.html.  \n",
        "§\n",
        ": http://host.robots.ox.ac.uk:8080/anonymous/XEDH10.html.\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>method</th>\n",
        "    <th>proposals</th>\n",
        "    <th>data</th>\n",
        "    <th>mAP(％)</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>SS</td>\n",
        "    <td>2000</td>\n",
        "    <td>12</td>\n",
        "    <td>65.7</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>SS</td>\n",
        "    <td>2000</td>\n",
        "    <td>07++12</td>\n",
        "    <td>68.4</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>RPN+VGG, shared†</td>\n",
        "    <td>300</td>\n",
        "    <td>12</td>\n",
        "    <td>67.0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>RPN+VGG, shared‡</td>\n",
        "    <td>300</td>\n",
        "    <td>07++12</td>\n",
        "    <td>70.4</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>RPN+VGG, shared§</td>\n",
        "    <td>300</td>\n",
        "    <td>COCO+07++12</td>\n",
        "    <td>75.9</td>\n",
        "  </tr>\n",
        "</table>\n",
        "<br>\n",
        "次に同データセットでK40 GPUで処理を行った際の処理速度。(指標値はfps)\n",
        "\n",
        "こちらもRPN+Fast R-CNNの方がかなり早い速度で処理が行われていることがわかる。  \n",
        "\n",
        "#### 参考箇所2：  \n",
        ">Table 5: Timing (ms) on a K40 GPU, except SS proposal is evaluated in a CPU. “Region-wise” includes NMS,\n",
        "pooling, fully-connected, and softmax layers. See our released code for the profiling of running time\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>model</th>\n",
        "    <th>system</th>\n",
        "    <th>conv</th>\n",
        "    <th>proposal</th>\n",
        "    <th>rigion-wise</th>\n",
        "    <th>total</th>\n",
        "    <th>rate</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>VGG</td>\n",
        "    <td>SS + Fast R-CNN</td>\n",
        "    <td>146</td>\n",
        "    <td>1510</td>\n",
        "    <td>174</td>\n",
        "    <td>1830</td>\n",
        "    <td>0.5fps</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>VGG</td>\n",
        "    <td>RPN + Fast R-CNN</td>\n",
        "    <td>141</td>\n",
        "    <td>10</td>\n",
        "    <td>47</td>\n",
        "    <td>198</td>\n",
        "    <td>5fps</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>ZF</td>\n",
        "    <td>RPN + Fast R-CNN</td>\n",
        "    <td>31</td>\n",
        "    <td>3</td>\n",
        "    <td>25</td>\n",
        "    <td>59</td>\n",
        "    <td>17fps</td>\n",
        "  </tr>\n",
        "</table>\n",
        "<br>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfLZnF8rSuWU",
        "colab_type": "text"
      },
      "source": [
        "(8) （アドバンス）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Vs_0QdML2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}