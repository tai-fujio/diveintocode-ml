{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint21-segmentation2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS0Muf-m9DhW",
        "colab_type": "text"
      },
      "source": [
        "## セグメンテーションの精度を改善する\n",
        "- 転移学習を用いる\n",
        "## 【問題1】コードレビュー\n",
        "- sprint20との違い\n",
        "- 転移学習をどのように行なっているか\n",
        "- コードのわからなかった部分にテキストで補足していく\n",
        "\n",
        "tgs-salt-identification-challenge data installation for colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGY_SZYE9Fnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge\n",
        "!unzip train.zip -d train\n",
        "!unzip test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ5d_lnO1GHK",
        "colab_type": "text"
      },
      "source": [
        "## Model architecture tuning & score optimization\n",
        "\n",
        "\n",
        "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
        "\n",
        "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
        "\n",
        "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
        "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
        "\n",
        "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LljsQi71GHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgl6V69j1GHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "did2tV4LuqQD",
        "colab_type": "text"
      },
      "source": [
        "- plt.rcParams['figure.figsize']  全体のfigsizeの設定に使う\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8jxPh5n1GHV",
        "colab_type": "text"
      },
      "source": [
        "### Data loading & depth merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z47QI2C1GHW",
        "colab_type": "code",
        "outputId": "c0d384cb-3820-47b9-d13c-5ef4a9184bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('sample_submission.csv')\n",
        "depth = pd.read_csv('depths.csv')\n",
        "\n",
        "train_src = 'train/'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id                                           rle_mask\n",
            "0  575d24d81d                                                NaN\n",
            "1  a266a2a9df                                          5051 5151\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
            "\n",
            "test:\n",
            "           id rle_mask\n",
            "0  155410d6fa      1 1\n",
            "1  78b32781d1      1 1\n",
            "2  63db2a476a      1 1\n",
            "3  17bfcdb967      1 1\n",
            "4  7ea0fd3c88      1 1\n",
            "\n",
            "           id                                           rle_mask    z\n",
            "0  575d24d81d                                                NaN  843\n",
            "1  a266a2a9df                                          5051 5151  794\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>rle_mask</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>575d24d81d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a266a2a9df</td>\n",
              "      <td>5051 5151</td>\n",
              "      <td>794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75efad62c1</td>\n",
              "      <td>9 93 109 94 210 94 310 95 411 95 511 96 612 96...</td>\n",
              "      <td>468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34e51dba6a</td>\n",
              "      <td>48 54 149 54 251 53 353 52 455 51 557 50 659 4...</td>\n",
              "      <td>727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4875705fb0</td>\n",
              "      <td>1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...</td>\n",
              "      <td>797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                           rle_mask    z\n",
              "0  575d24d81d                                                NaN  843\n",
              "1  a266a2a9df                                          5051 5151  794\n",
              "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
              "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
              "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-cLR7qf1GHZ",
        "colab_type": "text"
      },
      "source": [
        "### Load images and masks, examine random sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70jM_GP1GHZ",
        "colab_type": "code",
        "outputId": "31a02b32-0713-461a-8c27-fe3d2176f4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = np.asarray(\n",
        "    [cv2.imread('train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdip95YbysFM",
        "colab_type": "text"
      },
      "source": [
        "asarrayにするとcopy()されなくなり、参照渡しになる  \n",
        "https://punhundon-lifeshift.com/array_asarray  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1klOG5X61GHc",
        "colab_type": "code",
        "outputId": "4ab79a77-f370-41d4-984c-3a080bab5e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1d462e27f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clDFezhu1GHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32)\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUe-vZtl1Urq",
        "colab_type": "text"
      },
      "source": [
        "- compute_coverage()  \n",
        "maskしている割合(coverage)とクラス数(10%区切りで0~10の11段階に分割)(coverage_class)をinputのdfに付与する\n",
        "- create_depth_abs_channels()  \n",
        "深さの値の差分からボーダーを作成し、を各チャンネルに付与する  \n",
        "以下使い方のわからなかったライブラリ  \n",
        "[np.linspace()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html)  \n",
        "[np.diff()](https://docs.scipy.org/doc/numpy-1.10.4/reference/generated/numpy.diff.html)  \n",
        "[cv2.copyMakeBorder()](http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_core/py_basic_ops/py_basic_ops.html#id6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b2Y8VgR1GHf",
        "colab_type": "text"
      },
      "source": [
        "### Compute salt coverage (this will serve as a basis for stratified split):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0i2bmsA1GHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "komqCnz31GHi",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF3ez8QK1GHi",
        "colab_type": "code",
        "outputId": "203779d5-683c-4cea-8026-920cf5fe3b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
            "(804, 224, 224, 3) (804, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "506"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YtFtXG0OfET",
        "colab_type": "text"
      },
      "source": [
        "以降の関数はそもそもの理論から勉強したい  \n",
        "よって積み残し"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5k2dUUO1GHl",
        "colab_type": "text"
      },
      "source": [
        "### Loss functions & metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaSu3DnU1GHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7EY9j4U1GHo",
        "colab_type": "text"
      },
      "source": [
        "### Encoder features - ResNet50:\n",
        "\n",
        "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
        "Default input size will be assumed, which is (224, 224, 3).\n",
        "Layers will be as follows:\n",
        "\n",
        "- 'activation_1', shape: (None, 112, 112, 64)\n",
        "- 'activation_10', shape: (None, 56, 56, 256)\n",
        "- 'activation_22', shape: (None, 28, 28, 512)\n",
        "- 'activation_40', shape: (None, 14, 14, 1024)\n",
        "- 'activation_49', shape: (None, 7, 7, 2048)\n",
        "\n",
        "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwnVtsy31GHp",
        "colab_type": "text"
      },
      "source": [
        "### Decoder blocks:\n",
        "\n",
        "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
        "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyOTiY_i1GHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq1fRo2Y1GHr",
        "colab_type": "text"
      },
      "source": [
        "### Model definition(using resnet):\n",
        "\n",
        "Combine encoder and decoder blocks to create final segmentation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrCkLbmy1GHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    encoder1 = base_model.get_layer('activation_1').output\n",
        "    encoder2 = base_model.get_layer('activation_10').output\n",
        "    encoder3 = base_model.get_layer('activation_22').output\n",
        "    encoder4 = base_model.get_layer('activation_40').output\n",
        "    encoder5 = base_model.get_layer('activation_49').output\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfRtSkkS1GHy",
        "colab_type": "text"
      },
      "source": [
        "### Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "t4SZ_eQm1GHz",
        "colab_type": "code",
        "outputId": "6e1d9f80-fa12-486f-bd3c-3521d3f5bd64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10509
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "input_size = (224, 224, 3)\n",
        "\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0619 20:06:12.617283 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0619 20:06:12.619017 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0619 20:06:12.663243 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0619 20:06:12.664351 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0619 20:06:12.674353 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0619 20:06:15.611788 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0619 20:06:15.686900 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0619 20:06:25.402909 139797028599680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0619 20:06:25.965822 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0619 20:06:27.523053 139797028599680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0619 20:06:27.551636 139797028599680 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0619 20:06:27.583547 139797028599680 deprecation.py:323] From <ipython-input-10-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 48,978,353\n",
            "Trainable params: 48,919,953\n",
            "Non-trainable params: 58,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 160s 50ms/step - loss: 0.7030 - my_iou_metric: 0.3599 - val_loss: 1.0074 - val_my_iou_metric: 0.3373\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.33731, saving model to unet_resnet.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 114s 36ms/step - loss: 0.5328 - my_iou_metric: 0.5035 - val_loss: 1.9108 - val_my_iou_metric: 0.3179\n",
            "\n",
            "Epoch 00002: val_my_iou_metric did not improve from 0.33731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sh8tUM1JEhx",
        "colab_type": "text"
      },
      "source": [
        "- Sprint20との違い  \n",
        "1. アーキテクチャー\n",
        "下記summaryを参照\n",
        "2. 重みの初期値  \n",
        "sprint20 : ランダム初期値(重みがあればKerasのload_weightsでロード)\n",
        "sprint21 : imagenetで学習した重み\n",
        "3. 活性化関数  \n",
        "sprint20 : ReLu(outputはsigmoid)\n",
        "sprint21 : PReLu(outputはsigmoid)\n",
        "4. 損失関数  \n",
        "binary_crossentropy\n",
        "5. 最適化手法  \n",
        "Adam\n",
        "6. 評価手法  \n",
        "sprint20 : accuracy\n",
        "sprint21 : IoU\n",
        "7. 学習時間\n",
        "\n",
        "- 転移学習をどのようにおこなっているか  \n",
        "input ~ center block間でresnet、VGGのレイヤを適用させて学習させている(今回重みはimagenetを使用)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKD6HIVt1GH4",
        "colab_type": "text"
      },
      "source": [
        "### Validation set prediction and resizing to original size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAyErjcH1GH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZzOJC_a1GH8",
        "colab_type": "text"
      },
      "source": [
        "### Threshold optimization: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT0PyMcb1GH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVs8zRAS1GIB",
        "colab_type": "code",
        "outputId": "3cab5d63-8636-4e1b-c1ae-9fffe7c30d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:38<00:00,  1.11s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBBcMy8o1GIE",
        "colab_type": "code",
        "outputId": "6372ed85-f272-48df-ff2f-5fb3ac014d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.4350 at threshold: 0.880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.392452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.020484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.363682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.377363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.384701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.408831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.434950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.392452\n",
              "std     0.204939   0.020484\n",
              "min     0.200000   0.363682\n",
              "25%     0.370000   0.377363\n",
              "50%     0.540000   0.384701\n",
              "75%     0.710000   0.408831\n",
              "max     0.880000   0.434950"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez_DRKpU1GIH",
        "colab_type": "code",
        "outputId": "094e2c5e-0185-43d2-b4a4-50b3180b7463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2423dad278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkn+5lgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrGZgQc-HUzU",
        "colab_type": "text"
      },
      "source": [
        "## 【問題2】コードの書き換え\n",
        "## 【問題3】学習・推定\n",
        "- ResNetをVGGに書き換えて、学習・推定する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Og_8MWqNd6f",
        "colab_type": "text"
      },
      "source": [
        "### Model definition(using VGG16):\n",
        "\n",
        "Combine encoder and decoder blocks to create final segmentation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcZg_A8FNVbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_VGG16(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = VGG16(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    # Layers for feature extraction in the encoder part\n",
        "    encoder1 = base_model.get_layer('block1_pool').output\n",
        "    encoder2 = base_model.get_layer('block2_pool').output\n",
        "    encoder3 = base_model.get_layer('block3_pool').output\n",
        "    encoder4 = base_model.get_layer('block4_pool').output\n",
        "    encoder5 = base_model.get_layer('block5_pool').output\n",
        "    \n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShgYY-NvO-S2",
        "colab_type": "text"
      },
      "source": [
        "### Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RluqqT3YO8c3",
        "colab_type": "code",
        "outputId": "c13edcaf-af6b-4e95-f32f-a24f4346d893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4253
        }
      },
      "source": [
        "#K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "input_size = (224, 224, 3)\n",
        "\n",
        "model_depth = unet_VGG16(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_VGG16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 7, 7, 512)    0           dropout_19[0][0]                 \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 7, 7, 1024)   0           add_23[0][0]                     \n",
            "                                                                 block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 7, 7, 256)    0           dropout_22[0][0]                 \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 14, 14, 256)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_6[0][0]            \n",
            "                                                                 block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 14, 14, 128)  0           dropout_25[0][0]                 \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 28, 28, 128)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_7[0][0]            \n",
            "                                                                 block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 28, 28, 64)   0           dropout_28[0][0]                 \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2D)  (None, 56, 56, 64)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_8[0][0]            \n",
            "                                                                 block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 56, 56, 64)   0           dropout_31[0][0]                 \n",
            "                                                                 dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2D)  (None, 112, 112, 64) 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 112, 112, 128 0           up_sampling2d_9[0][0]            \n",
            "                                                                 block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling2D) (None, 224, 224, 128 0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 224, 224, 32) 0           dropout_34[0][0]                 \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 28,677,489\n",
            "Trainable params: 28,672,209\n",
            "Non-trainable params: 5,280\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 133s 41ms/step - loss: 0.8423 - my_iou_metric: 0.1951 - val_loss: 1.5245 - val_my_iou_metric: 0.2029\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.20286, saving model to unet_VGG16.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 110s 34ms/step - loss: 0.6472 - my_iou_metric: 0.3713 - val_loss: 1.5435 - val_my_iou_metric: 0.2315\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.20286 to 0.23147, saving model to unet_VGG16.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgoC3hsUlNCy",
        "colab_type": "text"
      },
      "source": [
        "### Validation set prediction and resizing to original size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2xYS6KulOpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVymXH0PlOyU",
        "colab_type": "text"
      },
      "source": [
        "### Threshold optimization: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_799P_alO87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9n8t4Qalg7g",
        "colab_type": "code",
        "outputId": "58b6f51c-067f-4365-fd18-37727f9d0adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:38<00:00,  1.10s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umKaMkHrlPY4",
        "colab_type": "code",
        "outputId": "caab795f-d50d-4dcf-b92d-9a7e3a1e4bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.4291 at threshold: 0.880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.316514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.048954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.255348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.275995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.299627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.348072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.429104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.316514\n",
              "std     0.204939   0.048954\n",
              "min     0.200000   0.255348\n",
              "25%     0.370000   0.275995\n",
              "50%     0.540000   0.299627\n",
              "75%     0.710000   0.348072\n",
              "max     0.880000   0.429104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQtQIkB6lqYC",
        "colab_type": "code",
        "outputId": "88ef933e-8868-4a30-fbbf-97efe5749eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f221bfd1d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAIaCAYAAADiE8FNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEl9ZJiWJEmS+uj/A1ucQCJziRJXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7ujYNmP1GIK",
        "colab_type": "text"
      },
      "source": [
        "## Conclusions:\n",
        "\n",
        "- Pretrained models can be used for segmentation problems:\n",
        "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
        "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
        "    - You can experiment with selection of layers for feature extraction\n",
        "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
        "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
        "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
        "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
        "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
        "\n",
        "\n",
        "### Possible experiments:\n",
        "\n",
        "- Change type of decoder block in created segmentation model\n",
        "- Create your own decoder blocks\n",
        "- Train with other losses\n",
        "- Train longer\n",
        "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
        "- Try different ranges and intervals for threshold optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpaz1sXi1GIK",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi13vLPNDeyG",
        "colab_type": "text"
      },
      "source": [
        "## code reading\n",
        "### Define UNet model for training.\n",
        "\n",
        "Taken from another kernel, thanks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkJf5vH4DfJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import Model\n",
        "from keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n",
        "                          Conv2DTranspose, Dropout, Input, MaxPooling2D,\n",
        "                          UpSampling2D, concatenate)\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def conv_block(m, dim, acti, bn, res, do=0):\n",
        "    n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "    n = BatchNormalization()(n) if bn else n\n",
        "    n = Dropout(do)(n) if do else n\n",
        "    n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
        "    n = BatchNormalization()(n) if bn else n\n",
        "    return Concatenate()([m, n]) if res else n\n",
        "\n",
        "\n",
        "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
        "    if depth > 0:\n",
        "        n = conv_block(m, dim, acti, bn, res)\n",
        "        m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
        "        m = level_block(m, int(inc * dim), depth - 1,\n",
        "                        inc, acti, do, bn, mp, up, res)\n",
        "        if up:\n",
        "            m = UpSampling2D()(m)\n",
        "            m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
        "        else:\n",
        "            m = Conv2DTranspose(dim, 3, strides=2,\n",
        "                                activation=acti, padding='same')(m)\n",
        "        n = Concatenate()([n, m])\n",
        "        m = conv_block(n, dim, acti, bn, res)\n",
        "    else:\n",
        "        m = conv_block(m, dim, acti, bn, res, do)\n",
        "    return m\n",
        "\n",
        "\n",
        "def UNet(params):\n",
        "\n",
        "    img_shape = params['input_dim']\n",
        "    out_ch = 1\n",
        "    start_ch = 8\n",
        "    depth = 3\n",
        "    inc_rate = 2.\n",
        "    activation = 'relu'\n",
        "    dropout = 0.5\n",
        "    batchnorm = False\n",
        "    maxpool = True\n",
        "    upconv = True\n",
        "    residual = False\n",
        "\n",
        "    i = Input(shape=img_shape)\n",
        "    o = level_block(i, start_ch, depth, inc_rate, activation,\n",
        "                    dropout, batchnorm, maxpool, upconv, residual)\n",
        "    o = Conv2D(out_ch, 1)(o)\n",
        "    # Sigmoid activation is used because model is trained with binary_crossentropy.\n",
        "    o =  Activation('sigmoid')(o)\n",
        "\n",
        "    model = Model(inputs=i, outputs=o)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkoTHKCsH-_D",
        "colab_type": "text"
      },
      "source": [
        "Resnetの方がiouが高くなった。  \n",
        "閾値は双方ともに1に近くなるほど、iouが上昇した。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8-yUW6XIPwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}