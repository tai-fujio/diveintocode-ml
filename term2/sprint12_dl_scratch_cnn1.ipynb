{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qh_pLx1EUT9-"
   },
   "source": [
    "下ごしらえ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6zN6LuTSUT9_",
    "outputId": "062e6b24-48c9-49ad-a73d-921f0dcc0dbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sys\n",
    "# ライブラリまでのディレクトリ定義\n",
    "#sys.path.append('../ml-scratch/utils') \n",
    "sys.path.append('../') # colaboratory用\n",
    "\n",
    "import fc, get_mini_batch, relu, soft_max, sgd, he_initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-b0LmYXVGs7"
   },
   "source": [
    "## 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAZ83L9yVI87"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    チャンネル数を1に限定した1次元畳み込み層クラス\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    stride : int\n",
    "      ストライド\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, W, B, optimizer, stride=1):\n",
    "        self.W = W\n",
    "        self.B = B\n",
    "        self.stride = stride\n",
    "        self.optimizer = optimizer\n",
    "        self.X = None\n",
    "        self.A = None\n",
    "        self.dW = np.zeros(len(W))\n",
    "        self.dX = None\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = X.copy()                                  # backwardで使うから\n",
    "        A = np.array([])                                   # 返却用\n",
    "        F_idx = np.arange(len(self.W))          # フィルタのindex\n",
    "        \n",
    "        # フィルタ終点がX終点にたどり着くまでやる\n",
    "        while F_idx[-1] <= len(self.X) - 1:\n",
    "            A = np.append(A, X[F_idx] @ self.W + self.B)\n",
    "            # フィルタをストライド分移動\n",
    "            F_idx += self.stride\n",
    "            \n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self, y, A):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            正解値\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.dX = np.zeros(len(self.X))         # 初期化\n",
    "        self.dA = y - A                                     # パラメータ更新で使うためインスタンス変数化\n",
    "        \n",
    "        d_idx = np.arange(len(self.W))     # deltaX計算用index\n",
    "        \n",
    "        # deltaA分やる\n",
    "        for s in range(len(self.dA)):\n",
    "            self.dX[d_idx] += self.dA[s] * self.W\n",
    "            d_idx += 1    # 右方向\n",
    "                    \n",
    "        # self.W self.Bの更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return self.dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1b9-uEEnATVJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGDCNN:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        \n",
    "        i_s_idx = np.arange(len(layer.W))     # deltaX計算用index\n",
    "        \n",
    "        # deltaA分やる\n",
    "        for s in range(len(layer.dA)):\n",
    "            layer.dW += layer.dA[s] * layer.X[i_s_idx]\n",
    "            i_s_idx += 1     # 右方向\n",
    "            \n",
    "        layer.W -= self.lr * layer.dW                # 重さ更新\n",
    "        \n",
    "        layer.dB = np.sum(layer.dA, axis=0)\n",
    "        layer.B -= self.lr * layer.dB                   # バイアス更新\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQlZejnUATVL"
   },
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KjrBoakVdrP"
   },
   "outputs": [],
   "source": [
    "def calc_output_size(n_in_size, f_size, st_size=1, pd_size=0):\n",
    "    return int(1 + (n_in_size + (2 * pd_size) - f_size / st_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yVQhur4VuXr"
   },
   "source": [
    "## 【問題3】小さな配列での1次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "qh504Zi6Vw-S",
    "outputId": "f39d1370-bd3e-4392-d7f7-d2578208dbdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A : [35. 50.]\n",
      "A no outputsize : 2\n",
      "dW : [ 50.  80. 110.]\n",
      "dB : 30.0\n",
      "dX : [ 30. 110. 170. 140.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4]).astype(np.float)    # float型じゃないとブロードキャストできない\n",
    "w = np.array([3, 5, 7]).astype(np.float)     # めんどくさいのでクラスで型変換は後回し\n",
    "b = 1\n",
    "\n",
    "sc1 = SimpleConv1d(w, b, SGDCNN(0.1))\n",
    "A = sc1.forward(x)\n",
    "print('A : %s' % A)\n",
    "print('A no outputsize : %s' % calc_output_size(len(sc1.X), len(sc1.W)))\n",
    "\n",
    "# 誤差\n",
    "y = np.array([45, 70])\n",
    "\n",
    "dX = sc1.backward(y, A)\n",
    "dW = sc1.dW\n",
    "dB = sc1.dB\n",
    "print('dW : %s' % dW)\n",
    "print('dB : %s' % dB)\n",
    "print('dX : %s' % dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "WqxZJauoATVT",
    "outputId": "1b5b1541-d2a5-4de5-c116-2909cd61aad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A : [ 71. 104. 135.]\n",
      "A no outputsize : 3\n",
      "dW : [-259. -374. -544. -693.]\n",
      "dB : -115.0\n",
      "dX : [ -78. -232. -517. -747. -691. -495.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4,6,7]).astype(np.float)\n",
    "w = np.array([3, 5, 7,9]).astype(np.float)\n",
    "b = 1\n",
    "\n",
    "sc1 = SimpleConv1d(w, b, SGDCNN(0.1))\n",
    "A = sc1.forward(x)\n",
    "print('A : %s' % A)\n",
    "print('A no outputsize : %s' % calc_output_size(len(sc1.X), len(sc1.W)))\n",
    "\n",
    "# 誤差\n",
    "y = np.array([45, 70, 80])\n",
    "\n",
    "dX = sc1.backward(y, A)\n",
    "dW = sc1.dW\n",
    "dB = sc1.dB\n",
    "print('dW : %s' % dW)\n",
    "print('dB : %s' % dB)\n",
    "print('dX : %s' % dX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7tLxE8mWMfQ"
   },
   "source": [
    "## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "## 【問題8】（アドバンス課題）任意のストライド数\n",
    "\n",
    "メモ：conv1D → H=1である必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1-Sl13mWRud"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    チャンネル数を1に限定した1次元畳み込み層クラス\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    stride : int\n",
    "      ストライド\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, W, B, optimizer, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.B = B\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.optimizer = optimizer\n",
    "        self.X = None\n",
    "        self.A = None\n",
    "        self.dW = None\n",
    "        self.dX = None\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        \n",
    "        if X.ndim < 3:\n",
    "            X = X[np.newaxis, :, :]\n",
    "            \n",
    "        self.X = X.copy()                                  # backwardで使うから\n",
    "        A = np.array([])                                   # 返却用\n",
    "        \n",
    "        S, C, W = X.shape\n",
    "        FN, C, FW = self.W.shape\n",
    "        \n",
    "        col = np.empty((0, FW * C))\n",
    "        col_W = self.W.reshape(FN, -1).T      # フィルタを平坦化\n",
    "        F_idx = np.arange(FW)                         # フィルタのindex\n",
    "        \n",
    "        while F_idx[-1] <= W - 1:                      # フィルタ終点がX終点にたどり着くまでやる\n",
    "            col = np.append(col, [X[:, :, F_idx].ravel()], axis=0)\n",
    "            F_idx += self.stride\n",
    "            \n",
    "        A = col @ col_W + self.B\n",
    "        \n",
    "        self.AC, self.AW = A.T.shape\n",
    "        \n",
    "        return A.T\n",
    "    \n",
    "    \n",
    "    def backward(self, A):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            正解値\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dX = np.zeros(self.X.shape)         # 初期化\n",
    "        self.dA = A.reshape((self.AC, self.AW))  # パラメータ更新で使うためインスタンス変数化\n",
    "        \n",
    "        S, C, W = self.dX.shape\n",
    "        FN, C, FW = self.W.shape\n",
    "        \n",
    "        W = np.sum(self.W.reshape(FW, -1), axis=1)\n",
    "        for i in range(S):                                            # バッチサイズ分ループ\n",
    "            for j in range(C):                                        # チャンネル数分ループ\n",
    "                d_idx = np.arange(FW)                        # deltaX計算用index\n",
    "                for s in range(self.dA.shape[1]):\n",
    "                    self.dX[i, j, d_idx] += np.sum(self.dA[:, s]) * W\n",
    "                    d_idx += 1    # 右方向\n",
    "        \n",
    "        # self.W self.Bの更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return self.dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VoNFqB7ATVZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGDCNN:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        \n",
    "        FN, C, FW = layer.W.shape\n",
    "        layer.dW = np.zeros((C, FW))\n",
    "        \n",
    "        for i in range(C):\n",
    "            i_s_idx = np.arange(FW)     # deltaX計算用index\n",
    "            for s in range(layer.dA.shape[1]):\n",
    "                layer.dW[i] += np.sum(layer.dA[:, s]) * np.sum(layer.X[:, i, i_s_idx], axis=0)\n",
    "                i_s_idx += 1     # 右方向\n",
    "            \n",
    "        layer.W -= self.lr * layer.dW                # 重さ更新\n",
    "        \n",
    "        layer.dB = np.sum(layer.dA, axis=1)\n",
    "        layer.B -= self.lr * layer.dB                   # バイアス更新\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "wsZS9iwDATVc",
    "outputId": "8f42fefb-b90d-4e3f-a510-0333ad4f0533",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A : [16. 22. 17. 23. 18. 24.]\n",
      "dW : [[189. 309. 429.]\n",
      " [309. 429. 549.]]\n",
      "W : [[[-17.9 -29.9 -41.9]\n",
      "  [-29.9 -41.9 -53.9]]\n",
      "\n",
      " [[-17.9 -29.9 -41.9]\n",
      "  [-29.9 -41.9 -53.9]]\n",
      "\n",
      " [[-17.9 -29.9 -41.9]\n",
      "  [-29.9 -41.9 -53.9]]]\n",
      "dB : [38. 40. 42.]\n",
      "B : [-2.8 -2.  -1.2]\n",
      "dX : [[[306. 720. 720. 414.]\n",
      "  [306. 720. 720. 414.]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]]]).astype(np.float) # shape(1, 2, 4)で、（バッチサイズ, 入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)).astype(np.float) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]).astype(np.float) # （出力チャンネル数）\n",
    "c1 = Conv1d(w, b, SGDCNN(0.1))\n",
    "A = c1.forward(x)\n",
    "\n",
    "A = A.ravel()\n",
    "\n",
    "dX = c1.backward(A)\n",
    "\n",
    "print('A : %s' % A.T)\n",
    "print('dW : %s' % c1.dW)\n",
    "print('W : %s' % c1.W)\n",
    "print('dB : %s' % c1.dB)\n",
    "print('B : %s' % c1.B)\n",
    "print('dX : %s' % dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "UP4aHrIcATVe",
    "outputId": "fd8fc1a7-7ed1-47b9-de46-5e88f493ebe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A : [[28. 37.]\n",
      " [29. 38.]\n",
      " [30. 39.]\n",
      " [31. 40.]]\n",
      "dW : [[ 426.  698.  970.]\n",
      " [ 698.  970. 1242.]\n",
      " [ 970. 1242. 1514.]]\n",
      "dB : [65. 67. 69. 71.]\n",
      "dX : [[[1416. 3264. 3264. 1848.]\n",
      "  [1416. 3264. 3264. 1848.]\n",
      "  [1416. 3264. 3264. 1848.]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3, 4], [2, 3, 4, 5], [3, 4, 5, 6]]]).astype(np.float)\n",
    "w = np.ones((4, 3, 3)).astype(np.float)\n",
    "b = np.array([1, 2, 3, 4]).astype(np.float)\n",
    "\n",
    "c1 = Conv1d(w, b, SGDCNN(0.1))\n",
    "A = c1.forward(x)\n",
    "\n",
    "dX = c1.backward(A)\n",
    "\n",
    "print('A : %s' % A)\n",
    "print('dW : %s' % c1.dW)\n",
    "print('dB : %s' % c1.dB)\n",
    "print('dX : %s' % dX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ca3XL2XUT-J"
   },
   "source": [
    "## 【問題5】学習・推定\n",
    "## CNN分類器クラスの作成\n",
    "- バッチサイズ1にしか対応していないため、X_trainのsample数を60000 → 6000に変更して行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGQ-6OvQUT-J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging                                                                     # ログ\n",
    "from datetime import datetime                                        # 時間のやつ\n",
    "from sklearn.preprocessing import OneHotEncoder       # ワンホットのやつ\n",
    "from tqdm import tqdm                                                     # 進捗バーを出してくれるやつ\n",
    "\n",
    "\n",
    "class Scratch1dCNNClassifier():\n",
    "    \"\"\"\n",
    "    ニューラルネットワーク分類器\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=1, n_epochs=5,  n_nodes=200, layer=4, verbose=True,\n",
    "                            sigma=1e-2, lr=1e-2, filter_n=3, filter_w=3, filter_c=1, activation=None, optimizer='sgd'):\n",
    "\n",
    "        self.batch_size = batch_size     # バッチサイズ\n",
    "        self.n_epochs = n_epochs         # エポック数 \n",
    "        self.n_input = n_nodes              # 初回のノード数\n",
    "        self.layer = layer                          # 層の数\n",
    "        self.verbose = verbose               # 学習過程出力フラグ\n",
    "        self.activation = activation        #活性化関数(文字列)\n",
    "        self.lr = lr                                      # 学習率\n",
    "        self.filter_n = filter_n                 # フィルタ枚数\n",
    "        self.filter_w = filter_w                # フィルタwidth\n",
    "        self.filter_c = filter_c                  # フィルタチャネル数\n",
    "        self.layer_instances = []             # 各層インスタンス格納用\n",
    "        self.activations = []                     # 活性化関数インスタンス格納用\n",
    "        self.loss_ = []                              # 学習用データの学習過程格納用\n",
    "        self.loss_val_ = []                       # 検証用データの学習過程格納用\n",
    "        \n",
    "        # 初期化・最適化クラスインスタンス作成\n",
    "        if activation == 'relu':\n",
    "            self.initializer = he_initializer.HeInitializer()\n",
    "        else:\n",
    "            self.initializer = XavierInitializer()\n",
    "        \n",
    "        if optimizer == 'sgd':\n",
    "            self.optimizer = sgd.SGD(lr)\n",
    "        elif optimizer == 'adagrad':\n",
    "            self.optimizer = AdaGrad(lr)\n",
    "            \n",
    "        # ワンホットライブラリのインスタンス作成\n",
    "        self.enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        \n",
    "        # ログレベルを DEBUG に変更\n",
    "        time_stamp = datetime.now().strftime('%Y%m%d')\n",
    "        logging.basicConfig(filename='../tmp/sprint11_' + time_stamp + '.log', level=logging.DEBUG)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # ワンホット化\n",
    "        y = self.enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        # 検証用データがある場合\n",
    "        if X_val is not None:\n",
    "            y_val= self.enc.fit_transform(y_val[:, np.newaxis])\n",
    "\n",
    "        # 初期化\n",
    "        n_nodes1 = self.n_input\n",
    "        out_w = calc_output_size(X.shape[2], 3)\n",
    "        n_features = out_w * self.filter_n\n",
    "        n_output = y.shape[1]\n",
    "        \n",
    "        # 各層のFCインスタンス作成\n",
    "        for i in range(self.layer):\n",
    "            if i == (self.layer - 1):     # 出力層\n",
    "                ins = fc.FC(n_nodes2, n_output, self.initializer, self.optimizer)\n",
    "                act_ins = soft_max.Softmax()\n",
    "            else:\n",
    "                if i == 0:                       # 入力層(conv)\n",
    "                    W = np.ones((self.filter_n, self.filter_c, self.filter_w)).astype(np.float)\n",
    "                    b = np.ones(self.filter_n).astype(np.float)\n",
    "                    ins = Conv1d(W, b, SGDCNN(self.lr))\n",
    "                elif i == 1:\n",
    "                    ins = fc.FC(n_features, n_nodes1, self.initializer, self.optimizer)\n",
    "                else:\n",
    "                    n_nodes2 = int(n_nodes1 / 2)\n",
    "                    ins = fc.FC(n_nodes1, n_nodes2, self.initializer, self.optimizer)\n",
    "                    n_nodes1 = n_nodes2\n",
    "                \n",
    "                # 出力層以外は指定された活性化関数をインスタンス化\n",
    "                if self.activation == 'sigmoid':\n",
    "                    act_ins = sigmoid.Sigmoid()\n",
    "                elif self.activation == 'tanh':\n",
    "                    act_ins = tanh.Tanh()\n",
    "                elif self.activation == 'relu':\n",
    "                    act_ins = relu.ReLU()\n",
    "                \n",
    "            self.layer_instances.append(ins)                           # 各自格納\n",
    "            self.activations.append(act_ins)\n",
    "\n",
    "\n",
    "        for e in tqdm(range(self.n_epochs)):\n",
    "            # ミニバッチ化\n",
    "            gmb = get_mini_batch.GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "            # ロス格納用\n",
    "            loss_ary = []\n",
    "            \n",
    "            # Xのn_samples / batch_size数分ループ処理\n",
    "            for mini_X_train, mini_y_train in gmb:\n",
    "                # forward propagation\n",
    "                for i in range(self.layer):\n",
    "                    if i == 0:                              # 入力層\n",
    "                        A = self.layer_instances[i].forward(mini_X_train)\n",
    "                        A = A.ravel()[np.newaxis, :]\n",
    "                        Z = self.activations[i].forward(A)\n",
    "                    else:\n",
    "                        A = self.layer_instances[i].forward(Z)\n",
    "                        Z = self.activations[i].forward(A)\n",
    "                \n",
    "                # back propagation\n",
    "                for i in range(self.layer):\n",
    "                    n_FC = self.layer - i - 1      # インスタンス逆指定用\n",
    "                    if i == 0:                               # 出力層\n",
    "                        dA, loss = self.activations[n_FC].backward(Z, mini_y_train)\n",
    "                        loss_ary.append(loss)\n",
    "                    else:                                     # 入力層\n",
    "                        dA = self.activations[n_FC].backward(dZ)\n",
    "                        \n",
    "                    dZ = self.layer_instances[n_FC].backward(dA)\n",
    "\n",
    "                    \n",
    "            #誤差を格納\n",
    "            self.loss_.append(np.mean(loss_ary))\n",
    "                        \n",
    "            # 検証用データがある場合\n",
    "            if X_val is not None:\n",
    "                # forward propagation\n",
    "                for i in range(self.layer):\n",
    "                    if i == 0:                              # 入力層\n",
    "                        A = self.layer_instances[i].forward(X_val)\n",
    "                        A = A.ravel()[np.newaxis, :]\n",
    "                        Z = self.activations[i].forward(A)\n",
    "                    else:\n",
    "                        A = self.layer_instances[i].forward(Z)\n",
    "                        Z = self.activations[i].forward(A)\n",
    "                \n",
    "                dA, loss_val = self.activations[self.layer-1].backward(Z, y_val)\n",
    "\n",
    "                #誤差を格納\n",
    "                self.loss_val_.append(np.mean(loss_val))\n",
    "                            \n",
    "\n",
    "            # フラグがTrueであればログ出力\n",
    "            if self.verbose:\n",
    "                logging.info('forward propagation %sエポック目 sum: %s shape: %s', e+1, np.sum(A), A.shape)\n",
    "                logging.info('forward propagation %sエポック目 sum: %s shape: %s', e+1, np.sum(Z), Z.shape)\n",
    "                logging.info('backward propagation %sエポック目 sum: %s shape: %s', e+1, np.sum(dA), dA.shape)\n",
    "                logging.info('backward propagation %sエポック目 sum: %s shape: %s', e+1, np.sum(dZ), dZ.shape)\n",
    "                logging.info('loss %sエポック目 : %s', e+1, np.sum(loss))\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred :  次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        \n",
    "        # ミニバッチ化\n",
    "        gmb = get_mini_batch.GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "        # ロス格納用\n",
    "        y_pred = np.empty(len(y))\n",
    "        print(y_pred.shape)\n",
    "        cnt = 0\n",
    "\n",
    "        # Xのn_samples / batch_size数分ループ処理\n",
    "        for mini_X_train, _ in gmb:\n",
    "            for i in range(self.layer):\n",
    "                if i == 0:                              # 入力層\n",
    "                    A = self.layer_instances[i].forward(mini_X_train)\n",
    "                    A = A.ravel()[np.newaxis, :]\n",
    "                    Z = self.activations[i].forward(A)\n",
    "                else:\n",
    "                    A = self.layer_instances[i].forward(Z)\n",
    "                    Z = self.activations[i].forward(A)\n",
    "                \n",
    "            y_pred[cnt] = np.argmax(Z[0], axis=0)\n",
    "            cnt += 1\n",
    "            \n",
    "        # 一番確率が高いラベルを予測値に\n",
    "        \n",
    "        \n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "611f-4PPFtc0"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 平坦化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# どでかいので少なくする\n",
    "X_train = X_train[:3000, np.newaxis, :]\n",
    "y_train = y_train[:3000]\n",
    "\n",
    "# 学習データをスプリット\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OVv8slGW82hW",
    "outputId": "679e2f2b-1623-41db-9d53-0b2d8342b788"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:56<00:00, 119.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Scratch1dCNNClassifier at 0x7f146d1eb278>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdnnc= Scratch1dCNNClassifier(activation='relu')\n",
    "\n",
    "sdnnc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "0_7p2JEyOa9Q",
    "outputId": "e84c4e0b-014d-4821-89f7-bee2ba850edf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFYWCiIhU+X+CE/wn7jG3IgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = np.array(sdnnc.loss_)\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "# Traing score\n",
    "plt.plot(train_loss, 'o-', color=\"r\", label=\"Train\")\n",
    "\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "FwULO2j9GioF",
    "outputId": "99a99590-fc04-40e0-cc98-5a015b577828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600,)\n",
      "[5. 6. 7. 8. 2. 2. 6. 3. 7. 7. 5. 0. 0. 1. 8. 9. 9. 2. 0. 1. 6. 6. 1. 5.\n",
      " 9. 3. 1. 9. 1. 9. 5. 0. 9. 0. 5. 7. 2. 4. 3. 1. 3. 6. 4. 6. 2. 0. 0. 9.\n",
      " 3. 1. 0. 0. 4. 6. 6. 4. 3. 5. 8. 1. 1. 8. 8. 1. 4. 4. 5. 1. 3. 4. 3. 4.\n",
      " 2. 1. 1. 3. 1. 2. 8. 7. 4. 3. 2. 0. 6. 1. 0. 6. 5. 9. 0. 2. 2. 4. 2. 1.\n",
      " 0. 0. 5. 0. 5. 3. 0. 6. 5. 2. 2. 0. 6. 0. 1. 1. 7. 6. 8. 5. 6. 7. 7. 6.\n",
      " 0. 1. 0. 4. 3. 0. 7. 1. 4. 2. 2. 2. 5. 6. 6. 7. 4. 0. 1. 4. 9. 2. 6. 0.\n",
      " 1. 2. 6. 3. 1. 0. 4. 6. 3. 9. 6. 3. 9. 8. 3. 8. 4. 3. 6. 3. 6. 5. 9. 9.\n",
      " 6. 1. 7. 0. 4. 6. 4. 8. 9. 7. 4. 1. 9. 4. 6. 5. 3. 7. 4. 5. 5. 9. 4. 9.\n",
      " 2. 8. 2. 8. 6. 4. 8. 4. 8. 2. 6. 4. 3. 3. 1. 3. 7. 3. 4. 3. 5. 7. 8. 2.\n",
      " 5. 4. 6. 5. 5. 2. 6. 9. 9. 0. 1. 6. 5. 0. 0. 5. 2. 7. 3. 1. 2. 2. 7. 0.\n",
      " 5. 1. 5. 3. 4. 9. 5. 3. 1. 7. 1. 2. 4. 7. 7. 7. 0. 4. 3. 1. 8. 3. 9. 5.\n",
      " 4. 5. 5. 0. 7. 2. 7. 9. 9. 1. 7. 1. 2. 3. 0. 6. 1. 1. 2. 4. 6. 3. 9. 0.\n",
      " 9. 2. 4. 5. 1. 2. 0. 7. 1. 7. 3. 8. 2. 8. 3. 2. 4. 1. 4. 1. 8. 0. 5. 7.\n",
      " 4. 9. 0. 2. 6. 7. 6. 1. 3. 2. 9. 8. 8. 8. 3. 2. 6. 5. 9. 8. 8. 3. 7. 1.\n",
      " 3. 9. 3. 1. 2. 2. 5. 3. 5. 4. 1. 3. 0. 9. 7. 4. 6. 3. 1. 1. 0. 4. 2. 6.\n",
      " 6. 7. 3. 9. 1. 3. 5. 3. 1. 9. 1. 7. 1. 2. 1. 6. 0. 2. 6. 9. 0. 3. 8. 1.\n",
      " 1. 7. 4. 3. 9. 0. 0. 7. 2. 5. 4. 5. 7. 2. 2. 9. 4. 1. 5. 5. 9. 4. 6. 7.\n",
      " 6. 2. 0. 6. 6. 8. 7. 9. 8. 6. 7. 5. 7. 2. 4. 2. 0. 1. 6. 0. 3. 4. 6. 5.\n",
      " 2. 2. 9. 4. 5. 4. 5. 3. 2. 6. 4. 6. 7. 3. 2. 6. 5. 6. 1. 1. 8. 9. 2. 8.\n",
      " 7. 2. 4. 2. 0. 2. 0. 7. 4. 6. 7. 8. 9. 2. 8. 4. 4. 0. 5. 2. 5. 9. 1. 5.\n",
      " 4. 3. 3. 7. 2. 9. 2. 4. 2. 1. 1. 3. 0. 6. 1. 3. 1. 6. 1. 2. 4. 9. 6. 6.\n",
      " 0. 9. 1. 8. 0. 3. 9. 6. 7. 7. 7. 4. 1. 7. 1. 8. 5. 9. 2. 0. 4. 3. 2. 6.\n",
      " 1. 9. 9. 7. 2. 7. 2. 7. 7. 1. 0. 3. 7. 4. 8. 4. 9. 3. 3. 9. 5. 4. 6. 1.\n",
      " 7. 3. 1. 7. 8. 6. 0. 7. 7. 1. 9. 6. 9. 8. 3. 4. 2. 8. 7. 1. 5. 3. 9. 1.\n",
      " 3. 7. 6. 5. 5. 4. 8. 4. 1. 1. 3. 1. 1. 2. 4. 5. 4. 0. 5. 9. 9. 4. 1. 5.]\n",
      "[[ 5 11  8  8  7  5  1  5  4  4]\n",
      " [ 5 12  8  8  6  8  9  7  3  7]\n",
      " [ 9 13  7 11  5  8  6  3  4  4]\n",
      " [ 5  6  7  7  9  4  7  8  3  3]\n",
      " [ 8  3  5  2  5  5  9  8  5  9]\n",
      " [ 7  6  7  8  3  6  4  9  5  2]\n",
      " [ 7  7  7  5 11  7  7  5  3  6]\n",
      " [ 2  9 10  7  9  1  9  4  4  6]\n",
      " [ 2  4  5  4  3  5  2  6  3  7]\n",
      " [ 5  7  4  3  8  6  9  4  4  7]]\n",
      "0.105\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "y_pred = sdnnc.predict(X_val, y_val)\n",
    "print(y_pred)\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfp2JmMz2rsf"
   },
   "source": [
    "ひどい。  \n",
    "<br>\n",
    "ものすごい学習に時間がかかるため\n",
    "- バッチサイズを大きくする\n",
    "- パディングを行う\n",
    "- 2d以上にする  \n",
    "場合は畳み込み時の処理を最適化(=im2col, col2imなどのライブラリを使う？)必要がありそうと感じた  \n",
    "<br>\n",
    "\n",
    "- 【問題6】（アドバンス課題）パディングの実装\n",
    "- 【問題7】（アドバンス課題）ミニバッチへの対応  \n",
    "上記はim2col, col2im を使う以外やり方が思いつかなかった(かといってfor文ループはあまりやりたくない。。)ので、飛ばしてしまった  \n",
    "次回sprint13は各ライブラリを使うことを前提とし、やってることを深掘りし理解を補完したい"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sprint12_dl_scratch_cnn1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
