{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint14_dnn_framework1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AC6hrlklQFg3"
      },
      "source": [
        "## TensorFlow キャッチアップ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l-cGrcsFQtTQ",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GsXEadRFOquG",
        "outputId": "965e9128-1e53-4c28-ddb8-b1746ec7ec3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# constant\n",
        "\n",
        "t1 = time.time() \n",
        "\n",
        "# 計算開始\n",
        "\n",
        "a = tf.constant(5)\n",
        "b = tf.constant(7)\n",
        "add = tf.add(a, b)\n",
        "\n",
        "print(add)                               # エッジの説明が格納されているだけ\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(add)     # Session.run()にエッジを格納すると計算がなされる\n",
        "    print(output) # 12\n",
        "sess.close()\n",
        "\n",
        "# 計算終了\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "elapsed_time = t2-t1\n",
        "print(f\"経過時間：{elapsed_time}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Add_13:0\", shape=(), dtype=int32)\n",
            "12\n",
            "経過時間：0.0179288387298584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wmuQwh_DPpAG",
        "outputId": "d7b65dd8-278c-4dcc-8320-519d52d4d93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 処理前の時刻\n",
        "t1 = time.time() \n",
        "\n",
        "# 計算開始\n",
        "\n",
        "a_n = np.array(5)\n",
        "b_n = np.array(7)\n",
        "output_n = np.add(a_n, b_n)\n",
        "print(output_n) # 12\n",
        "\n",
        "# 計算終了\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "elapsed_time = t2-t1\n",
        "print(f\"経過時間：{elapsed_time}\")\n",
        "\n",
        "# 簡単な計算だとNumpyのが早い・記述も楽"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "経過時間：0.0005831718444824219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0MKxvIpuP7SL",
        "outputId": "bd43cc06-aacc-4eb7-b8be-d540f294312a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# placeholder\n",
        "\n",
        "t1 = time.time() \n",
        "\n",
        "# 計算開始\n",
        "\n",
        "c = tf.placeholder(tf.int32)\n",
        "d = tf.placeholder(tf.int32)\n",
        "add = tf.add(c, d)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(add, feed_dict={c:5, d:7})\n",
        "    print(output) # 12\n",
        "sess.close()\n",
        "# 計算終了\n",
        "\n",
        "t2 = time.time()\n",
        "elapsed_time = t2-t1\n",
        "print(f\"経過時間：{elapsed_time}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "経過時間：0.017274141311645508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HBCWzxApXRmh"
      },
      "source": [
        "- ロジスティック回帰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jNe3o96aWaG7",
        "colab": {}
      },
      "source": [
        "# 入力が1, 1の場合にのみ1と出力したい\n",
        "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y_train = np.array([[0],[0],[0],[1]])\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 2])\n",
        "t = tf.placeholder(tf.float32, [None, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b0ZH7wteXz-q",
        "colab": {}
      },
      "source": [
        "# Valiable → 学習により更新を行う値であることを宣言(重み・バイアスなど)\n",
        "\n",
        "W = tf.Variable(tf.zeros([2,1]))\n",
        "b = tf.Variable(tf.zeros([1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "63vdekMNYQop",
        "colab": {}
      },
      "source": [
        "# matmul → np.dotに近い挙動\n",
        "y = tf.sigmoid(tf.matmul(x, W) + b)\n",
        "\n",
        "# クロスエントロピー誤差\n",
        "cross_entropy = tf.reduce_sum(-t * tf.log(y) - (1 - t) * tf.log(1 - y))\n",
        "\n",
        "# 二乗和誤差\n",
        "sse = tf.reduce_sum(tf.square(y - t))\n",
        "\n",
        "# 勾配降下法(0.1は学習率)\n",
        "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
        "\n",
        "# 予測・正確度\n",
        "correct_prediction = tf.equal(tf.sign(y - 0.5), tf.sign(t - 0.5))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# 上記のエッジはrunできんかった\n",
        "\n",
        "#with tf.Session() as sess:\n",
        "    #output1 = sess.run(y)\n",
        "    #output2 = sess.run(cross_entropy)\n",
        "    #output3 = sess.run(sse)\n",
        "    #output4 = sess.run(train_step)\n",
        "    #output5 = sess.run(correct_prediction)\n",
        "    #output6 = sess.run(accuracy)\n",
        "#sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jS1qkJzpZ4TU",
        "outputId": "823179d3-a26d-45f0-c576-92b74eca7495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "# 初期化\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# 学習\n",
        "for epoch in range(1000):\n",
        "    sess.run(train_step, feed_dict={\n",
        "        x:x_train,\n",
        "        t:y_train\n",
        "    })\n",
        "    # 100回ごとに正解率を表示\n",
        "    if epoch % 100 == 0:\n",
        "        acc_val = sess.run(\n",
        "            accuracy, feed_dict={\n",
        "                x:x_train,\n",
        "                t:y_train})\n",
        "        print (f'epoch: {epoch}, Accuracy: {acc_val}')\n",
        "        \n",
        "        # h_thetaの確認\n",
        "        mat = tf.matmul(x, W)\n",
        "        y = tf.sigmoid(mat + b)\n",
        "        \n",
        "        mat = sess.run(mat, feed_dict={\n",
        "            x:x_train,\n",
        "            t:y_train\n",
        "        })\n",
        "        \n",
        "        print(f'mat: {mat} mat.shape: {mat.shape}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, Accuracy: 0.75\n",
            "mat: [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] mat.shape: (4, 1)\n",
            "epoch: 100, Accuracy: 1.0\n",
            "mat: [[0.       ]\n",
            " [1.7671356]\n",
            " [1.7671356]\n",
            " [3.5342712]] mat.shape: (4, 1)\n",
            "epoch: 200, Accuracy: 1.0\n",
            "mat: [[0.      ]\n",
            " [2.702048]\n",
            " [2.702048]\n",
            " [5.404096]] mat.shape: (4, 1)\n",
            "epoch: 300, Accuracy: 1.0\n",
            "mat: [[0.      ]\n",
            " [3.345771]\n",
            " [3.345771]\n",
            " [6.691542]] mat.shape: (4, 1)\n",
            "epoch: 400, Accuracy: 1.0\n",
            "mat: [[0.       ]\n",
            " [3.8412285]\n",
            " [3.8412285]\n",
            " [7.682457 ]] mat.shape: (4, 1)\n",
            "epoch: 500, Accuracy: 1.0\n",
            "mat: [[0.      ]\n",
            " [4.244355]\n",
            " [4.244355]\n",
            " [8.48871 ]] mat.shape: (4, 1)\n",
            "epoch: 600, Accuracy: 1.0\n",
            "mat: [[0.       ]\n",
            " [4.5839767]\n",
            " [4.5839767]\n",
            " [9.1679535]] mat.shape: (4, 1)\n",
            "epoch: 700, Accuracy: 1.0\n",
            "mat: [[0.       ]\n",
            " [4.8771544]\n",
            " [4.8771544]\n",
            " [9.754309 ]] mat.shape: (4, 1)\n",
            "epoch: 800, Accuracy: 1.0\n",
            "mat: [[ 0.       ]\n",
            " [ 5.1348853]\n",
            " [ 5.1348853]\n",
            " [10.269771 ]] mat.shape: (4, 1)\n",
            "epoch: 900, Accuracy: 1.0\n",
            "mat: [[ 0.     ]\n",
            " [ 5.36469]\n",
            " [ 5.36469]\n",
            " [10.72938]] mat.shape: (4, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D9p4vINsYnCn",
        "outputId": "bd5eb6f9-36d2-483c-8d7f-f02ea831e2c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#学習結果が正しいか確認\n",
        "classified = sess.run(correct_prediction, feed_dict={\n",
        "    x:x_train,\n",
        "    t:y_train\n",
        "})\n",
        "\n",
        "#出力yの確認\n",
        "prob = sess.run(y, feed_dict={\n",
        "    x:x_train,\n",
        "    t:y_train\n",
        "})\n",
        "\n",
        "print(classified)\n",
        "\n",
        "print(prob)\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n",
            "[[1.9648671e-04]\n",
            " [4.9049795e-02]\n",
            " [4.9049795e-02]\n",
            " [9.3120372e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5hB_SymmgRgX"
      },
      "source": [
        "## 【問題1】スクラッチを振り返る  \n",
        "どのような実装をしたかを列挙する\n",
        "- 重みの初期化\n",
        "- エポックのループ\n",
        "- パラメータの更新\n",
        "- 誤差の計算・保持\n",
        "- 予測(predict・predict_proba)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HqQIFaf-xM3k"
      },
      "source": [
        "## 【問題2】スクラッチとTensorFlowの対応を考える"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWIYqLpFauZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      学習データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inG6MsaCauZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def example_net(x):\n",
        "    \"\"\"\n",
        "    単純な3層ニューラルネットワーク\n",
        "    \"\"\"\n",
        "\n",
        "    # 重みとバイアスの宣言\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
        "    return layer_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Moe3yhHIw25q",
        "outputId": "62bdd6cb-5b1c-420d-deca-ddb2cccc8548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# データセットの読み込み\n",
        "dataset_path =\"Iris.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "# データフレームから条件抽出\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "# ラベルを数値に変換\n",
        "y[y=='Iris-versicolor'] = 0\n",
        "y[y=='Iris-virginica'] = 1\n",
        "y = y.astype(np.int)[:, np.newaxis]\n",
        "\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "# 最適化手法\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# variableの初期化\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        # エポックごとにループ\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # ミニバッチごとにループ\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss : 37.0548, val_loss : 31.6318, acc : 0.250, val_acc : 0.625\n",
            "Epoch 1, loss : 8.3026, val_loss : 24.7911, acc : 0.750, val_acc : 0.375\n",
            "Epoch 2, loss : 5.4770, val_loss : 15.2191, acc : 0.750, val_acc : 0.688\n",
            "Epoch 3, loss : 0.1323, val_loss : 7.7516, acc : 1.000, val_acc : 0.500\n",
            "Epoch 4, loss : 3.2350, val_loss : 12.1814, acc : 0.750, val_acc : 0.688\n",
            "Epoch 5, loss : 0.0874, val_loss : 7.7894, acc : 1.000, val_acc : 0.500\n",
            "Epoch 6, loss : 0.0000, val_loss : 5.0974, acc : 1.000, val_acc : 0.750\n",
            "Epoch 7, loss : 0.0000, val_loss : 3.9478, acc : 1.000, val_acc : 0.750\n",
            "Epoch 8, loss : 0.0000, val_loss : 3.2221, acc : 1.000, val_acc : 0.875\n",
            "Epoch 9, loss : 0.0000, val_loss : 1.5515, acc : 1.000, val_acc : 0.875\n",
            "test_acc : 0.800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ixcXEcD5D9fC"
      },
      "source": [
        "## 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W2d8w-egxT3M",
        "outputId": "b05e3bfb-eb4d-47b9-a529-d344853f66e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "# データセットの読み込み\n",
        "dataset_path =\"Iris.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "# ワンホットライブラリのインスタンス作成\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y = enc.fit_transform(y[:, np.newaxis])\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 3\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "# 最適化手法\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.argmax(Y,1),tf.argmax(tf.nn.softmax(logits),1))\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "# variableの初期化\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        # エポックごとにループ\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # ミニバッチごとにループ\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-24d7eb979c5e>:36: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Epoch 0, loss : 1.8643, val_loss : 1.9158, acc : 0.833, val_acc : 0.833\n",
            "Epoch 1, loss : 2.7703, val_loss : 2.6188, acc : 0.667, val_acc : 0.833\n",
            "Epoch 2, loss : 1.2170, val_loss : 3.6050, acc : 0.833, val_acc : 0.792\n",
            "Epoch 3, loss : 0.0446, val_loss : 2.3526, acc : 1.000, val_acc : 0.875\n",
            "Epoch 4, loss : 0.0000, val_loss : 0.4288, acc : 1.000, val_acc : 0.917\n",
            "Epoch 5, loss : 0.0000, val_loss : 1.5085, acc : 1.000, val_acc : 0.917\n",
            "Epoch 6, loss : 0.0000, val_loss : 0.3945, acc : 1.000, val_acc : 0.875\n",
            "Epoch 7, loss : 0.0000, val_loss : 0.8306, acc : 1.000, val_acc : 0.875\n",
            "Epoch 8, loss : 0.0000, val_loss : 1.3256, acc : 1.000, val_acc : 0.917\n",
            "Epoch 9, loss : 0.7531, val_loss : 6.3527, acc : 0.667, val_acc : 0.708\n",
            "test_acc : 0.667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GGY3DEUcz_Ho"
      },
      "source": [
        "## 【問題4】House Pricesのモデルを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3pkohEbz1c5V",
        "outputId": "5b9a1116-f004-46b4-d40f-54a24f4394bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "# データセットの読み込み\n",
        "dataset_path =\"train.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "y = df[\"SalePrice\"]\n",
        "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
        "y = np.array(y)\n",
        "y = y[:, np.newaxis]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(y)\n",
        "y = scaler.transform(y)\n",
        "\n",
        "X = np.array(X)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 1e-5\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, 1])\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.square(Y - logits))\n",
        "# 最適化手法\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
        "# variableの初期化\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        # エポックごとにループ\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # ミニバッチごとにループ\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss = sess.run(loss_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "        total_loss /= n_samples\n",
        "        val_loss = sess.run(loss_op, feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}\".format(epoch, loss, val_loss))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss : 504.4492, val_loss : 1194.7134\n",
            "Epoch 1, loss : 483.1086, val_loss : 1141.0264\n",
            "Epoch 2, loss : 462.2194, val_loss : 1089.1327\n",
            "Epoch 3, loss : 441.9364, val_loss : 1039.2843\n",
            "Epoch 4, loss : 422.2136, val_loss : 991.6172\n",
            "Epoch 5, loss : 403.2039, val_loss : 946.0821\n",
            "Epoch 6, loss : 384.9580, val_loss : 902.5712\n",
            "Epoch 7, loss : 367.4388, val_loss : 861.0481\n",
            "Epoch 8, loss : 350.6330, val_loss : 821.4575\n",
            "Epoch 9, loss : 334.5052, val_loss : 783.7001\n",
            "Epoch 10, loss : 319.0035, val_loss : 747.6428\n",
            "Epoch 11, loss : 304.1477, val_loss : 713.2308\n",
            "Epoch 12, loss : 289.8966, val_loss : 680.3714\n",
            "Epoch 13, loss : 276.2477, val_loss : 649.0452\n",
            "Epoch 14, loss : 263.2149, val_loss : 619.2173\n",
            "Epoch 15, loss : 250.6988, val_loss : 590.8048\n",
            "Epoch 16, loss : 238.6835, val_loss : 563.7975\n",
            "Epoch 17, loss : 227.1550, val_loss : 538.1102\n",
            "Epoch 18, loss : 216.0928, val_loss : 513.6505\n",
            "Epoch 19, loss : 205.4890, val_loss : 490.3732\n",
            "Epoch 20, loss : 195.3773, val_loss : 468.2406\n",
            "Epoch 21, loss : 185.7261, val_loss : 447.2132\n",
            "Epoch 22, loss : 176.4846, val_loss : 427.2587\n",
            "Epoch 23, loss : 167.6482, val_loss : 408.3079\n",
            "Epoch 24, loss : 159.1989, val_loss : 390.3224\n",
            "Epoch 25, loss : 151.1168, val_loss : 373.2489\n",
            "Epoch 26, loss : 143.3930, val_loss : 357.0589\n",
            "Epoch 27, loss : 136.0172, val_loss : 341.6761\n",
            "Epoch 28, loss : 128.9800, val_loss : 327.0748\n",
            "Epoch 29, loss : 122.2649, val_loss : 313.2279\n",
            "Epoch 30, loss : 115.8628, val_loss : 300.0921\n",
            "Epoch 31, loss : 109.7674, val_loss : 287.6383\n",
            "Epoch 32, loss : 103.9722, val_loss : 275.8239\n",
            "Epoch 33, loss : 98.4654, val_loss : 264.6438\n",
            "Epoch 34, loss : 93.2405, val_loss : 254.0583\n",
            "Epoch 35, loss : 88.2822, val_loss : 244.0373\n",
            "Epoch 36, loss : 83.5859, val_loss : 234.5596\n",
            "Epoch 37, loss : 79.1455, val_loss : 225.5999\n",
            "Epoch 38, loss : 74.9543, val_loss : 217.1307\n",
            "Epoch 39, loss : 71.0004, val_loss : 209.1200\n",
            "Epoch 40, loss : 67.2758, val_loss : 201.5532\n",
            "Epoch 41, loss : 63.7711, val_loss : 194.4019\n",
            "Epoch 42, loss : 60.4779, val_loss : 187.6572\n",
            "Epoch 43, loss : 57.3864, val_loss : 181.2875\n",
            "Epoch 44, loss : 54.4882, val_loss : 175.2787\n",
            "Epoch 45, loss : 51.7746, val_loss : 169.6109\n",
            "Epoch 46, loss : 49.2428, val_loss : 164.2618\n",
            "Epoch 47, loss : 46.8816, val_loss : 159.2109\n",
            "Epoch 48, loss : 44.6834, val_loss : 154.4409\n",
            "Epoch 49, loss : 42.6411, val_loss : 149.9400\n",
            "Epoch 50, loss : 40.7462, val_loss : 145.6791\n",
            "Epoch 51, loss : 38.9910, val_loss : 141.6484\n",
            "Epoch 52, loss : 37.3678, val_loss : 137.8362\n",
            "Epoch 53, loss : 35.8709, val_loss : 134.2275\n",
            "Epoch 54, loss : 34.4889, val_loss : 130.8089\n",
            "Epoch 55, loss : 33.2169, val_loss : 127.5670\n",
            "Epoch 56, loss : 32.0490, val_loss : 124.4835\n",
            "Epoch 57, loss : 30.9759, val_loss : 121.5537\n",
            "Epoch 58, loss : 29.9948, val_loss : 118.7724\n",
            "Epoch 59, loss : 29.0995, val_loss : 116.1234\n",
            "Epoch 60, loss : 28.2824, val_loss : 113.5945\n",
            "Epoch 61, loss : 27.5377, val_loss : 111.1786\n",
            "Epoch 62, loss : 26.8581, val_loss : 108.8785\n",
            "Epoch 63, loss : 26.2411, val_loss : 106.6760\n",
            "Epoch 64, loss : 25.6796, val_loss : 104.5633\n",
            "Epoch 65, loss : 25.1720, val_loss : 102.5371\n",
            "Epoch 66, loss : 24.7129, val_loss : 100.5875\n",
            "Epoch 67, loss : 24.3008, val_loss : 98.7059\n",
            "Epoch 68, loss : 23.9149, val_loss : 96.8907\n",
            "Epoch 69, loss : 23.5526, val_loss : 95.1345\n",
            "Epoch 70, loss : 23.2251, val_loss : 93.4334\n",
            "Epoch 71, loss : 22.9295, val_loss : 91.7843\n",
            "Epoch 72, loss : 22.6647, val_loss : 90.1844\n",
            "Epoch 73, loss : 22.4279, val_loss : 88.6262\n",
            "Epoch 74, loss : 22.2129, val_loss : 87.1074\n",
            "Epoch 75, loss : 22.0200, val_loss : 85.6297\n",
            "Epoch 76, loss : 21.8484, val_loss : 84.1916\n",
            "Epoch 77, loss : 21.6974, val_loss : 82.7860\n",
            "Epoch 78, loss : 21.5650, val_loss : 81.4125\n",
            "Epoch 79, loss : 21.4498, val_loss : 80.0680\n",
            "Epoch 80, loss : 21.3496, val_loss : 78.7523\n",
            "Epoch 81, loss : 21.2631, val_loss : 77.4687\n",
            "Epoch 82, loss : 21.1887, val_loss : 76.2124\n",
            "Epoch 83, loss : 21.1247, val_loss : 74.9794\n",
            "Epoch 84, loss : 21.0716, val_loss : 73.7692\n",
            "Epoch 85, loss : 21.0252, val_loss : 72.5828\n",
            "Epoch 86, loss : 20.9872, val_loss : 71.4189\n",
            "Epoch 87, loss : 20.9513, val_loss : 70.2773\n",
            "Epoch 88, loss : 20.9229, val_loss : 69.1569\n",
            "Epoch 89, loss : 20.9031, val_loss : 68.0616\n",
            "Epoch 90, loss : 20.8908, val_loss : 66.9881\n",
            "Epoch 91, loss : 20.8856, val_loss : 65.9328\n",
            "Epoch 92, loss : 20.8838, val_loss : 64.8921\n",
            "Epoch 93, loss : 20.8879, val_loss : 63.8703\n",
            "Epoch 94, loss : 20.8969, val_loss : 62.8664\n",
            "Epoch 95, loss : 20.9105, val_loss : 61.8800\n",
            "Epoch 96, loss : 20.9275, val_loss : 60.9138\n",
            "Epoch 97, loss : 20.9478, val_loss : 59.9652\n",
            "Epoch 98, loss : 20.9691, val_loss : 59.0327\n",
            "Epoch 99, loss : 20.9917, val_loss : 58.1203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbQThDY0LHI7",
        "colab_type": "text"
      },
      "source": [
        "## 【問題5】MNISTのモデルを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G8A3cBRLN0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7f3e7f85-b166-4d6c-e17f-bc36cbdc12ae"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 平坦化\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "# 前処理\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# ワンホットライブラリのインスタンス作成\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
        "\n",
        "\n",
        "# 学習データをスプリット\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 10\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "# 最適化手法\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.argmax(Y,1),tf.argmax(tf.nn.softmax(logits),1))\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "# variableの初期化\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        # エポックごとにループ\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # ミニバッチごとにループ\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss : 1.3353, val_loss : 1.2701, acc : 0.600, val_acc : 0.664\n",
            "Epoch 1, loss : 0.8308, val_loss : 2.0287, acc : 0.700, val_acc : 0.550\n",
            "Epoch 2, loss : 0.7625, val_loss : 0.9362, acc : 0.700, val_acc : 0.707\n",
            "Epoch 3, loss : 0.2680, val_loss : 0.6330, acc : 0.900, val_acc : 0.866\n",
            "Epoch 4, loss : 0.5722, val_loss : 0.4824, acc : 0.800, val_acc : 0.887\n",
            "Epoch 5, loss : 0.4279, val_loss : 0.4697, acc : 0.900, val_acc : 0.895\n",
            "Epoch 6, loss : 0.4857, val_loss : 0.4011, acc : 0.900, val_acc : 0.910\n",
            "Epoch 7, loss : 0.7445, val_loss : 0.3637, acc : 0.900, val_acc : 0.915\n",
            "Epoch 8, loss : 0.4065, val_loss : 0.3369, acc : 0.900, val_acc : 0.921\n",
            "Epoch 9, loss : 0.2142, val_loss : 0.3636, acc : 0.900, val_acc : 0.920\n",
            "test_acc : 0.923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2uW_-oAQD-W-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "f2c117ac-8def-439a-e3f8-8f18b2a668c5"
      },
      "source": [
        "tf.summary.FileWriter('test', sess.graph)\n",
        "!tensorboard --logdir=test --port=8010"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.13.1 at http://d0e87c770357:8010 (Press CTRL+C to quit)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LSlFMAQo1fX5"
      },
      "source": [
        "http://localhost:8010"
      ]
    }
  ]
}