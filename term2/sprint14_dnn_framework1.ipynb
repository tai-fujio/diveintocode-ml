{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AC6hrlklQFg3"
   },
   "source": [
    "## TensorFlow キャッチアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-cGrcsFQtTQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "GsXEadRFOquG",
    "outputId": "965e9128-1e53-4c28-ddb8-b1746ec7ec3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n",
      "12\n",
      "経過時間：0.0711517333984375\n"
     ]
    }
   ],
   "source": [
    "# constant\n",
    "\n",
    "t1 = time.time() \n",
    "\n",
    "# 計算開始\n",
    "\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(7)\n",
    "add = tf.add(a, b)\n",
    "\n",
    "print(add)                               # エッジの説明が格納されているだけ\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(add)     # Session.run()にエッジを格納すると計算がなされる\n",
    "    print(output) # 12\n",
    "sess.close()\n",
    "\n",
    "# 計算終了\n",
    "\n",
    "\n",
    "t2 = time.time()\n",
    "elapsed_time = t2-t1\n",
    "print(f\"経過時間：{elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wmuQwh_DPpAG",
    "outputId": "d7b65dd8-278c-4dcc-8320-519d52d4d93f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "経過時間：0.0016109943389892578\n"
     ]
    }
   ],
   "source": [
    "# 処理前の時刻\n",
    "t1 = time.time() \n",
    "\n",
    "# 計算開始\n",
    "\n",
    "a_n = np.array(5)\n",
    "b_n = np.array(7)\n",
    "output_n = np.add(a_n, b_n)\n",
    "print(output_n) # 12\n",
    "\n",
    "# 計算終了\n",
    "\n",
    "\n",
    "t2 = time.time()\n",
    "elapsed_time = t2-t1\n",
    "print(f\"経過時間：{elapsed_time}\")\n",
    "\n",
    "# 簡単な計算だとNumpyのが早い・記述も楽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0MKxvIpuP7SL",
    "outputId": "bd43cc06-aacc-4eb7-b8be-d540f294312a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "経過時間：0.0311431884765625\n"
     ]
    }
   ],
   "source": [
    "# placeholder\n",
    "\n",
    "t1 = time.time() \n",
    "\n",
    "# 計算開始\n",
    "\n",
    "c = tf.placeholder(tf.int32)\n",
    "d = tf.placeholder(tf.int32)\n",
    "add = tf.add(c, d)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(add, feed_dict={c:5, d:7})\n",
    "    print(output) # 12\n",
    "sess.close()\n",
    "# 計算終了\n",
    "\n",
    "t2 = time.time()\n",
    "elapsed_time = t2-t1\n",
    "print(f\"経過時間：{elapsed_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBCWzxApXRmh"
   },
   "source": [
    "- ロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNe3o96aWaG7"
   },
   "outputs": [],
   "source": [
    "# 入力が1, 1の場合にのみ1と出力したい\n",
    "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_train = np.array([[0],[0],[0],[1]])\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "t = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0ZH7wteXz-q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Valiable → 学習により更新を行う値であることを宣言(重み・バイアスなど)\n",
    "\n",
    "W = tf.Variable(tf.zeros([2,1]))\n",
    "b = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63vdekMNYQop"
   },
   "outputs": [],
   "source": [
    "# matmul → np.dotに近い挙動\n",
    "y = tf.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "# クロスエントロピー誤差\n",
    "cross_entropy = tf.reduce_sum(-t * tf.log(y) - (1 - t) * tf.log(1 - y))\n",
    "\n",
    "# 二乗和誤差\n",
    "sse = tf.reduce_sum(tf.square(y - t))\n",
    "\n",
    "# 勾配降下法(0.1は学習率)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "# 予測・正確度\n",
    "correct_prediction = tf.equal(tf.sign(y - 0.5), tf.sign(t - 0.5))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 上記のエッジはrunできんかった\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "    #output1 = sess.run(y)\n",
    "    #output2 = sess.run(cross_entropy)\n",
    "    #output3 = sess.run(sse)\n",
    "    #output4 = sess.run(train_step)\n",
    "    #output5 = sess.run(correct_prediction)\n",
    "    #output6 = sess.run(accuracy)\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "jS1qkJzpZ4TU",
    "outputId": "823179d3-a26d-45f0-c576-92b74eca7495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Accuracy: 0.75\n",
      "mat: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] mat.shape: (4, 1)\n",
      "epoch: 100, Accuracy: 1.0\n",
      "mat: [[0.       ]\n",
      " [1.7671354]\n",
      " [1.7671354]\n",
      " [3.5342708]] mat.shape: (4, 1)\n",
      "epoch: 200, Accuracy: 1.0\n",
      "mat: [[0.       ]\n",
      " [2.7020476]\n",
      " [2.7020476]\n",
      " [5.404095 ]] mat.shape: (4, 1)\n",
      "epoch: 300, Accuracy: 1.0\n",
      "mat: [[0.       ]\n",
      " [3.3457706]\n",
      " [3.3457706]\n",
      " [6.691541 ]] mat.shape: (4, 1)\n",
      "epoch: 400, Accuracy: 1.0\n",
      "mat: [[0.       ]\n",
      " [3.8412278]\n",
      " [3.8412278]\n",
      " [7.6824555]] mat.shape: (4, 1)\n",
      "epoch: 500, Accuracy: 1.0\n",
      "mat: [[0.       ]\n",
      " [4.2443547]\n",
      " [4.2443547]\n",
      " [8.488709 ]] mat.shape: (4, 1)\n",
      "epoch: 600, Accuracy: 1.0\n",
      "mat: [[0.       ]\n",
      " [4.5839763]\n",
      " [4.5839763]\n",
      " [9.167953 ]] mat.shape: (4, 1)\n",
      "epoch: 700, Accuracy: 1.0\n",
      "mat: [[0.       ]\n",
      " [4.8771544]\n",
      " [4.8771544]\n",
      " [9.754309 ]] mat.shape: (4, 1)\n",
      "epoch: 800, Accuracy: 1.0\n",
      "mat: [[ 0.      ]\n",
      " [ 5.134886]\n",
      " [ 5.134886]\n",
      " [10.269772]] mat.shape: (4, 1)\n",
      "epoch: 900, Accuracy: 1.0\n",
      "mat: [[ 0.       ]\n",
      " [ 5.3646903]\n",
      " [ 5.3646903]\n",
      " [10.729381 ]] mat.shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# 初期化\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 学習\n",
    "for epoch in range(1000):\n",
    "    sess.run(train_step, feed_dict={\n",
    "        x:x_train,\n",
    "        t:y_train\n",
    "    })\n",
    "    # 100回ごとに正解率を表示\n",
    "    if epoch % 100 == 0:\n",
    "        acc_val = sess.run(\n",
    "            accuracy, feed_dict={\n",
    "                x:x_train,\n",
    "                t:y_train})\n",
    "        print (f'epoch: {epoch}, Accuracy: {acc_val}')\n",
    "        \n",
    "        # h_thetaの確認\n",
    "        mat = tf.matmul(x, W)\n",
    "        y = tf.sigmoid(mat + b)\n",
    "        \n",
    "        mat = sess.run(mat, feed_dict={\n",
    "            x:x_train,\n",
    "            t:y_train\n",
    "        })\n",
    "        \n",
    "        print(f'mat: {mat} mat.shape: {mat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "D9p4vINsYnCn",
    "outputId": "bd5eb6f9-36d2-483c-8d7f-f02ea831e2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "[[1.9651403e-04]\n",
      " [4.9049813e-02]\n",
      " [4.9049813e-02]\n",
      " [9.3120378e-01]]\n"
     ]
    }
   ],
   "source": [
    "#学習結果が正しいか確認\n",
    "classified = sess.run(correct_prediction, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "})\n",
    "\n",
    "#出力yの確認\n",
    "prob = sess.run(y, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "})\n",
    "\n",
    "print(classified)\n",
    "\n",
    "print(prob)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hB_SymmgRgX"
   },
   "source": [
    "## 【問題1】スクラッチを振り返る  \n",
    "どのような実装をしたかを列挙する\n",
    "- 重みの初期化\n",
    "- エポックのループ\n",
    "- パラメータの更新\n",
    "- 誤差の計算・保持\n",
    "- 予測(predict・predict_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HqQIFaf-xM3k"
   },
   "source": [
    "## 【問題2】スクラッチとTensorFlowの対応を考える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWIYqLpFauZQ"
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inG6MsaCauZT"
   },
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Moe3yhHIw25q",
    "outputId": "62bdd6cb-5b1c-420d-deca-ddb2cccc8548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 22.8356, val_loss : 19.8720, acc : 0.264, val_acc : 0.375\n",
      "Epoch 1, loss : 6.8833, val_loss : 18.7509, acc : 0.579, val_acc : 0.375\n",
      "Epoch 2, loss : 9.9303, val_loss : 5.8811, acc : 0.593, val_acc : 0.688\n",
      "Epoch 3, loss : 14.1241, val_loss : 0.6215, acc : 0.600, val_acc : 0.812\n",
      "Epoch 4, loss : 4.3075, val_loss : 6.1609, acc : 0.650, val_acc : 0.500\n",
      "Epoch 5, loss : 1.8243, val_loss : 5.5370, acc : 0.764, val_acc : 0.750\n",
      "Epoch 6, loss : 2.6288, val_loss : 1.2717, acc : 0.757, val_acc : 0.750\n",
      "Epoch 7, loss : 0.2713, val_loss : 1.9777, acc : 0.914, val_acc : 0.812\n",
      "Epoch 8, loss : 0.9131, val_loss : 1.2201, acc : 0.900, val_acc : 0.750\n",
      "Epoch 9, loss : 0.2710, val_loss : 2.9284, acc : 0.943, val_acc : 0.750\n",
      "test_acc : 0.850\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= total_batch\n",
    "        total_acc /= total_batch\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, total_loss, val_loss, total_acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixcXEcD5D9fC"
   },
   "source": [
    "## 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "W2d8w-egxT3M",
    "outputId": "b05e3bfb-eb4d-47b9-a529-d344853f66e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-74668afc2d37>:37: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch 0, loss : 114.8081, val_loss : 89.8024, acc : 0.417, val_acc : 0.333\n",
      "Epoch 1, loss : 45.6915, val_loss : 24.6353, acc : 0.543, val_acc : 0.708\n",
      "Epoch 2, loss : 11.0043, val_loss : 7.2815, acc : 0.693, val_acc : 0.667\n",
      "Epoch 3, loss : 3.4904, val_loss : 2.4033, acc : 0.830, val_acc : 0.792\n",
      "Epoch 4, loss : 1.0554, val_loss : 1.5530, acc : 0.900, val_acc : 0.833\n",
      "Epoch 5, loss : 0.5179, val_loss : 1.9067, acc : 0.930, val_acc : 0.833\n",
      "Epoch 6, loss : 0.5192, val_loss : 1.8226, acc : 0.940, val_acc : 0.833\n",
      "Epoch 7, loss : 0.6219, val_loss : 1.2121, acc : 0.940, val_acc : 0.833\n",
      "Epoch 8, loss : 0.2517, val_loss : 1.1525, acc : 0.980, val_acc : 0.833\n",
      "Epoch 9, loss : 0.1923, val_loss : 2.2351, acc : 0.970, val_acc : 0.833\n",
      "test_acc : 0.933\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ワンホットライブラリのインスタンス作成\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y = enc.fit_transform(y[:, np.newaxis])\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "# 最適化手法\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.argmax(Y,1),tf.argmax(tf.nn.softmax(logits),1))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= total_batch\n",
    "        total_acc /= total_batch\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, total_loss, val_loss, total_acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGY3DEUcz_Ho"
   },
   "source": [
    "## 【問題4】House Pricesのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "3pkohEbz1c5V",
    "outputId": "5b9a1116-f004-46b4-d40f-54a24f4394bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 811.3356, val_loss : 920.3372\n",
      "Epoch 1, loss : 767.1091, val_loss : 870.9540\n",
      "Epoch 2, loss : 724.1913, val_loss : 823.4835\n",
      "Epoch 3, loss : 683.1694, val_loss : 778.1200\n",
      "Epoch 4, loss : 644.0872, val_loss : 734.8495\n",
      "Epoch 5, loss : 606.9163, val_loss : 693.6569\n",
      "Epoch 6, loss : 571.6033, val_loss : 654.4589\n",
      "Epoch 7, loss : 538.0743, val_loss : 617.1747\n",
      "Epoch 8, loss : 506.2599, val_loss : 581.7506\n",
      "Epoch 9, loss : 476.1117, val_loss : 548.1446\n",
      "Epoch 10, loss : 447.5836, val_loss : 516.2942\n",
      "Epoch 11, loss : 420.5955, val_loss : 486.0966\n",
      "Epoch 12, loss : 395.0997, val_loss : 457.4789\n",
      "Epoch 13, loss : 371.0163, val_loss : 430.4111\n",
      "Epoch 14, loss : 348.3041, val_loss : 404.8032\n",
      "Epoch 15, loss : 326.8840, val_loss : 380.5890\n",
      "Epoch 16, loss : 306.7097, val_loss : 357.7462\n",
      "Epoch 17, loss : 287.7322, val_loss : 336.1806\n",
      "Epoch 18, loss : 269.8801, val_loss : 315.8680\n",
      "Epoch 19, loss : 253.1116, val_loss : 296.7597\n",
      "Epoch 20, loss : 237.3959, val_loss : 278.7966\n",
      "Epoch 21, loss : 222.6847, val_loss : 261.9191\n",
      "Epoch 22, loss : 208.9229, val_loss : 246.0773\n",
      "Epoch 23, loss : 196.0640, val_loss : 231.2231\n",
      "Epoch 24, loss : 184.0604, val_loss : 217.3106\n",
      "Epoch 25, loss : 172.8669, val_loss : 204.3011\n",
      "Epoch 26, loss : 162.4339, val_loss : 192.1467\n",
      "Epoch 27, loss : 152.7294, val_loss : 180.8142\n",
      "Epoch 28, loss : 143.7176, val_loss : 170.2609\n",
      "Epoch 29, loss : 135.3605, val_loss : 160.4301\n",
      "Epoch 30, loss : 127.6216, val_loss : 151.2785\n",
      "Epoch 31, loss : 120.4587, val_loss : 142.7649\n",
      "Epoch 32, loss : 113.8305, val_loss : 134.8611\n",
      "Epoch 33, loss : 107.7002, val_loss : 127.5242\n",
      "Epoch 34, loss : 102.0351, val_loss : 120.7181\n",
      "Epoch 35, loss : 96.8009, val_loss : 114.4064\n",
      "Epoch 36, loss : 91.9649, val_loss : 108.5424\n",
      "Epoch 37, loss : 87.4973, val_loss : 103.0997\n",
      "Epoch 38, loss : 83.3710, val_loss : 98.0486\n",
      "Epoch 39, loss : 79.5594, val_loss : 93.3661\n",
      "Epoch 40, loss : 76.0382, val_loss : 89.0240\n",
      "Epoch 41, loss : 72.7821, val_loss : 84.9947\n",
      "Epoch 42, loss : 69.7725, val_loss : 81.2556\n",
      "Epoch 43, loss : 66.9902, val_loss : 77.7860\n",
      "Epoch 44, loss : 64.4141, val_loss : 74.5632\n",
      "Epoch 45, loss : 62.0249, val_loss : 71.5656\n",
      "Epoch 46, loss : 59.8078, val_loss : 68.7807\n",
      "Epoch 47, loss : 57.7485, val_loss : 66.1916\n",
      "Epoch 48, loss : 55.8313, val_loss : 63.7752\n",
      "Epoch 49, loss : 54.0421, val_loss : 61.5214\n",
      "Epoch 50, loss : 52.3676, val_loss : 59.4163\n",
      "Epoch 51, loss : 50.7983, val_loss : 57.4479\n",
      "Epoch 52, loss : 49.3277, val_loss : 55.6025\n",
      "Epoch 53, loss : 47.9454, val_loss : 53.8729\n",
      "Epoch 54, loss : 46.6437, val_loss : 52.2529\n",
      "Epoch 55, loss : 45.4157, val_loss : 50.7311\n",
      "Epoch 56, loss : 44.2543, val_loss : 49.2991\n",
      "Epoch 57, loss : 43.1583, val_loss : 47.9520\n",
      "Epoch 58, loss : 42.1176, val_loss : 46.6803\n",
      "Epoch 59, loss : 41.1261, val_loss : 45.4736\n",
      "Epoch 60, loss : 40.1796, val_loss : 44.3290\n",
      "Epoch 61, loss : 39.2771, val_loss : 43.2439\n",
      "Epoch 62, loss : 38.4146, val_loss : 42.2098\n",
      "Epoch 63, loss : 37.5843, val_loss : 41.2224\n",
      "Epoch 64, loss : 36.7840, val_loss : 40.2768\n",
      "Epoch 65, loss : 36.0136, val_loss : 39.3709\n",
      "Epoch 66, loss : 35.2719, val_loss : 38.5000\n",
      "Epoch 67, loss : 34.5563, val_loss : 37.6623\n",
      "Epoch 68, loss : 33.8633, val_loss : 36.8555\n",
      "Epoch 69, loss : 33.1897, val_loss : 36.0779\n",
      "Epoch 70, loss : 32.5345, val_loss : 35.3260\n",
      "Epoch 71, loss : 31.8975, val_loss : 34.5973\n",
      "Epoch 72, loss : 31.2778, val_loss : 33.8924\n",
      "Epoch 73, loss : 30.6740, val_loss : 33.2074\n",
      "Epoch 74, loss : 30.0850, val_loss : 32.5410\n",
      "Epoch 75, loss : 29.5101, val_loss : 31.8930\n",
      "Epoch 76, loss : 28.9477, val_loss : 31.2595\n",
      "Epoch 77, loss : 28.3953, val_loss : 30.6391\n",
      "Epoch 78, loss : 27.8555, val_loss : 30.0350\n",
      "Epoch 79, loss : 27.3267, val_loss : 29.4440\n",
      "Epoch 80, loss : 26.8069, val_loss : 28.8650\n",
      "Epoch 81, loss : 26.2950, val_loss : 28.2982\n",
      "Epoch 82, loss : 25.7944, val_loss : 27.7439\n",
      "Epoch 83, loss : 25.3046, val_loss : 27.2014\n",
      "Epoch 84, loss : 24.8255, val_loss : 26.6712\n",
      "Epoch 85, loss : 24.3567, val_loss : 26.1550\n",
      "Epoch 86, loss : 23.8965, val_loss : 25.6509\n",
      "Epoch 87, loss : 23.4441, val_loss : 25.1581\n",
      "Epoch 88, loss : 23.0003, val_loss : 24.6765\n",
      "Epoch 89, loss : 22.5653, val_loss : 24.2056\n",
      "Epoch 90, loss : 22.1394, val_loss : 23.7456\n",
      "Epoch 91, loss : 21.7211, val_loss : 23.2947\n",
      "Epoch 92, loss : 21.3116, val_loss : 22.8545\n",
      "Epoch 93, loss : 20.9133, val_loss : 22.4253\n",
      "Epoch 94, loss : 20.5240, val_loss : 22.0060\n",
      "Epoch 95, loss : 20.1428, val_loss : 21.5967\n",
      "Epoch 96, loss : 19.7693, val_loss : 21.1966\n",
      "Epoch 97, loss : 19.4033, val_loss : 20.8062\n",
      "Epoch 98, loss : 19.0443, val_loss : 20.4246\n",
      "Epoch 99, loss : 18.6927, val_loss : 20.0519\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"train.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = np.array(y)\n",
    "y = y[:, np.newaxis]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(y)\n",
    "y = scaler.transform(y)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 1e-5\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.square(Y - logits))\n",
    "# 最適化手法\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss = sess.run(loss_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "        total_loss /= total_batch\n",
    "        val_loss = sess.run(loss_op, feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}\".format(epoch, total_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbQThDY0LHI7"
   },
   "source": [
    "## 【問題5】MNISTのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "8G8A3cBRLN0z",
    "outputId": "7f3e7f85-b166-4d6c-e17f-bc36cbdc12ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 5.2219, val_loss : 1.2961, acc : 0.613, val_acc : 0.594\n",
      "Epoch 1, loss : 1.0964, val_loss : 1.0921, acc : 0.660, val_acc : 0.654\n",
      "Epoch 2, loss : 0.8183, val_loss : 0.8194, acc : 0.758, val_acc : 0.765\n",
      "Epoch 3, loss : 0.6274, val_loss : 0.6594, acc : 0.824, val_acc : 0.846\n",
      "Epoch 4, loss : 0.4310, val_loss : 0.4281, acc : 0.886, val_acc : 0.897\n",
      "Epoch 5, loss : 0.3388, val_loss : 0.3925, acc : 0.913, val_acc : 0.908\n",
      "Epoch 6, loss : 0.3063, val_loss : 0.3965, acc : 0.923, val_acc : 0.907\n",
      "Epoch 7, loss : 0.2913, val_loss : 0.3606, acc : 0.928, val_acc : 0.911\n",
      "Epoch 8, loss : 0.2704, val_loss : 0.3705, acc : 0.932, val_acc : 0.909\n",
      "Epoch 9, loss : 0.2678, val_loss : 0.3517, acc : 0.932, val_acc : 0.913\n",
      "test_acc : 0.918\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 平坦化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ワンホットライブラリのインスタンス作成\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "\n",
    "\n",
    "# 学習データをスプリット\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "# 最適化手法\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.argmax(Y,1),tf.argmax(tf.nn.softmax(logits),1))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= total_batch\n",
    "        total_acc /= total_batch\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, total_loss, val_loss, total_acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "id": "2uW_-oAQD-W-",
    "outputId": "f2c117ac-8def-439a-e3f8-8f18b2a668c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0530 18:10:16.106097 123145563852800 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0530 18:10:16.118995 123145563852800 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0530 18:10:16.130365 123145563852800 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "TensorBoard 1.13.1 at http://TnoMacBook-Air.local:8010 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "tf.summary.FileWriter('test', sess.graph)\n",
    "!tensorboard --logdir=test --port=8010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSlFMAQo1fX5"
   },
   "source": [
    "http://localhost:8010"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sprint14_dnn_framework1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
